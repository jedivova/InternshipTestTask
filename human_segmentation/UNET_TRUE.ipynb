{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем статью, читаем про свертки (https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d ).\n",
    "\n",
    "Строим аналогичную, указанной в статье, архитектуру сети.\n",
    "Грузим картинки, нормируем до 1.\n",
    "Аугментация - картинки генерятся на лету, на входе в очередную эпоху. Метод - повороты, растягивания сжатия, сдвиги, отражение по горизонтали.\n",
    "\n",
    "Коэфф Дайса ~0.95 на проверочных данных.\n",
    "Аугментация данных точность не повышает, поэтому оставил блок с обучением без аугментации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "from lib import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 240\n",
    "IMG_HEIGHT = 320\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS model of U-net and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:17<00:00, 73.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:06<00:00, 210.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get train imgs and masks\n",
    "X_train = Get_IMGs('data\\\\train\\\\')/255\n",
    "Y_train = Get_Masks('data\\\\train_mask\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 способа обучения\n",
    "Странный момент - в способе без аугментации max batch_size=16 (выше - ошибка), но в 2 способе получилось поднять до 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 way - без аугментации\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "                    callbacks=[checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 way - аугментация на лету\n",
    "# Fit model\n",
    "datagen = ImageDataGenerator(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='constant'\n",
    ")\n",
    "\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_1.h5', verbose=1, save_best_only=True)\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=50,callbacks=[checkpointer], shuffle=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 way to train, \"more manual\"\n",
    "datagen = ImageDataGenerator(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='constant'\n",
    ")\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint('model_1.h5', verbose=1, save_best_only=True)\n",
    "for e in range(10):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n",
    "        results = model.fit(X_train, Y_train, validation_split=0.1,batch_size=16,\n",
    "                    callbacks=[checkpointer], verbose=0)\n",
    "        batches += 1\n",
    "        if batches >= len(X_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model on validation images, save to csv and get Dice metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 145/145 [00:02<00:00, 70.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 205.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice metric for valid imgs: 0.9436904476184572\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_1.h5', custom_objects={'dice_coef': dice_coef})\n",
    "valid_imgs = Get_IMGs('data\\\\valid\\\\') #get np.array with images\n",
    "valid_true_masks = Get_Masks('data\\\\valid_mask\\\\')#get np.array with masks\n",
    "\n",
    "valid_pred_masks = (model.predict(valid_imgs/255)> 0.5).astype(np.uint8) #get predicted masks\n",
    "\n",
    "# Save valid rle_masks to pred_valid_template.csv\n",
    "df = pd.DataFrame({\n",
    "        'id': [int(x.split('.')[0]) for x in next(os.walk('data\\\\valid\\\\'))[2]],\n",
    "        'rle_mask': [encode_rle(mask) for mask in np.squeeze(valid_pred_masks)]\n",
    "})\n",
    "df.to_csv('data/pred_valid_template.csv',index=False)  #save to csv\n",
    "\n",
    "#Check Dice metric\n",
    "Dice_metric = get_dice(np.squeeze(valid_true_masks), np.squeeze(valid_pred_masks))\n",
    "print('Dice metric for valid imgs:', Dice_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice metric for valid imgs: 0.951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image, true mask and predicted mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8d279e4fe84bebac37b35fe61ef4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=145), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(valid_imgs),1))\n",
    "def g(i=0):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('image')\n",
    "    plt.imshow(valid_imgs[i,:,:])\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('true mask')\n",
    "    plt.imshow(valid_true_masks[i,:,:,0])\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('mask predicted')\n",
    "    plt.imshow(valid_pred_masks[i,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get masks from test images and create examples.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 74.56it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = Get_IMGs('data/test/') \n",
    "\n",
    "# Predict masks for test imgs\n",
    "model = load_model('model_1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "test_pred_masks = model.predict(test_imgs)\n",
    "test_pred_masks = np.squeeze(test_pred_masks > 0.5).astype(np.uint8)*255 \n",
    "# without *255 masks, putted in example.html, will look like black rectangle\n",
    "\n",
    "# Save to html\n",
    "paths_to_imgs = sorted(glob(\"data\\\\test\\\\*\"))\n",
    "_ = get_html(paths_to_imgs, test_pred_masks, path_to_save=\"results\\\\example\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
