{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "from lib import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 240\n",
    "IMG_HEIGHT = 320\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS model of U-net and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:22<00:00, 57.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:07<00:00, 172.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get train imgs and masks\n",
    "X_train = Get_IMGs('data\\\\train\\\\') \n",
    "Y_train = Get_Masks('data\\\\train_mask\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_1.h5', verbose=1, save_best_only=True)\n",
    "#results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "#                    callbacks=[checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "42/41 [==============================] - ETA: 5:15 - loss: 0.8086 - acc: 0.471 - ETA: 2:41 - loss: 0.7640 - acc: 0.504 - ETA: 1:50 - loss: 0.7523 - acc: 0.532 - ETA: 1:24 - loss: 0.7432 - acc: 0.544 - ETA: 1:08 - loss: 0.7333 - acc: 0.551 - ETA: 57s - loss: 0.7228 - acc: 0.559 - ETA: 50s - loss: 0.7110 - acc: 0.57 - ETA: 44s - loss: 0.7006 - acc: 0.58 - ETA: 39s - loss: 0.7139 - acc: 0.58 - ETA: 35s - loss: 0.7086 - acc: 0.58 - ETA: 32s - loss: 0.7059 - acc: 0.58 - ETA: 29s - loss: 0.7014 - acc: 0.58 - ETA: 27s - loss: 0.6967 - acc: 0.59 - ETA: 25s - loss: 0.6957 - acc: 0.59 - ETA: 23s - loss: 0.6920 - acc: 0.59 - ETA: 21s - loss: 0.6888 - acc: 0.59 - ETA: 20s - loss: 0.6901 - acc: 0.59 - ETA: 18s - loss: 0.6868 - acc: 0.59 - ETA: 17s - loss: 0.6849 - acc: 0.59 - ETA: 16s - loss: 0.6825 - acc: 0.60 - ETA: 15s - loss: 0.6797 - acc: 0.60 - ETA: 14s - loss: 0.6763 - acc: 0.60 - ETA: 13s - loss: 0.6740 - acc: 0.60 - ETA: 12s - loss: 0.6711 - acc: 0.61 - ETA: 11s - loss: 0.6688 - acc: 0.61 - ETA: 10s - loss: 0.6648 - acc: 0.61 - ETA: 9s - loss: 0.6602 - acc: 0.6230 - ETA: 8s - loss: 0.6595 - acc: 0.625 - ETA: 7s - loss: 0.6557 - acc: 0.628 - ETA: 7s - loss: 0.6533 - acc: 0.631 - ETA: 6s - loss: 0.6513 - acc: 0.633 - ETA: 5s - loss: 0.6485 - acc: 0.636 - ETA: 5s - loss: 0.6464 - acc: 0.638 - ETA: 4s - loss: 0.6444 - acc: 0.640 - ETA: 3s - loss: 0.6417 - acc: 0.643 - ETA: 3s - loss: 0.6400 - acc: 0.645 - ETA: 2s - loss: 0.6383 - acc: 0.647 - ETA: 1s - loss: 0.6361 - acc: 0.649 - ETA: 1s - loss: 0.6349 - acc: 0.651 - ETA: 0s - loss: 0.6327 - acc: 0.653 - ETA: 0s - loss: 0.6312 - acc: 0.654 - 25s 583ms/step - loss: 0.6285 - acc: 0.6576\n",
      "Epoch 2/10\n",
      "42/41 [==============================] - ETA: 15s - loss: 0.5510 - acc: 0.73 - ETA: 15s - loss: 0.5545 - acc: 0.73 - ETA: 15s - loss: 0.5466 - acc: 0.74 - ETA: 14s - loss: 0.5514 - acc: 0.73 - ETA: 14s - loss: 0.5421 - acc: 0.74 - ETA: 14s - loss: 0.5508 - acc: 0.74 - ETA: 13s - loss: 0.5526 - acc: 0.74 - ETA: 13s - loss: 0.5464 - acc: 0.74 - ETA: 12s - loss: 0.5459 - acc: 0.74 - ETA: 12s - loss: 0.5487 - acc: 0.74 - ETA: 12s - loss: 0.5513 - acc: 0.73 - ETA: 11s - loss: 0.5494 - acc: 0.73 - ETA: 11s - loss: 0.5452 - acc: 0.74 - ETA: 10s - loss: 0.5403 - acc: 0.74 - ETA: 10s - loss: 0.5409 - acc: 0.74 - ETA: 10s - loss: 0.5387 - acc: 0.74 - ETA: 9s - loss: 0.5362 - acc: 0.7479 - ETA: 9s - loss: 0.5335 - acc: 0.749 - ETA: 8s - loss: 0.5306 - acc: 0.751 - ETA: 8s - loss: 0.5296 - acc: 0.751 - ETA: 8s - loss: 0.5294 - acc: 0.751 - ETA: 7s - loss: 0.5307 - acc: 0.750 - ETA: 7s - loss: 0.5295 - acc: 0.751 - ETA: 6s - loss: 0.5292 - acc: 0.751 - ETA: 6s - loss: 0.5275 - acc: 0.752 - ETA: 6s - loss: 0.5259 - acc: 0.753 - ETA: 5s - loss: 0.5266 - acc: 0.752 - ETA: 5s - loss: 0.5257 - acc: 0.752 - ETA: 4s - loss: 0.5235 - acc: 0.753 - ETA: 4s - loss: 0.5211 - acc: 0.755 - ETA: 4s - loss: 0.5211 - acc: 0.755 - ETA: 3s - loss: 0.5195 - acc: 0.756 - ETA: 3s - loss: 0.5182 - acc: 0.756 - ETA: 2s - loss: 0.5165 - acc: 0.757 - ETA: 2s - loss: 0.5161 - acc: 0.757 - ETA: 1s - loss: 0.5170 - acc: 0.757 - ETA: 1s - loss: 0.5174 - acc: 0.757 - ETA: 1s - loss: 0.5170 - acc: 0.758 - ETA: 0s - loss: 0.5169 - acc: 0.758 - ETA: 0s - loss: 0.5158 - acc: 0.758 - ETA: 0s - loss: 0.5156 - acc: 0.759 - 16s 392ms/step - loss: 0.5149 - acc: 0.7597\n",
      "Epoch 3/10\n",
      "42/41 [==============================] - ETA: 2s - loss: 0.4536 - acc: 0.802 - ETA: 9s - loss: 0.4670 - acc: 0.789 - ETA: 11s - loss: 0.4791 - acc: 0.78 - ETA: 11s - loss: 0.4837 - acc: 0.77 - ETA: 12s - loss: 0.4818 - acc: 0.77 - ETA: 12s - loss: 0.4916 - acc: 0.77 - ETA: 12s - loss: 0.4881 - acc: 0.77 - ETA: 11s - loss: 0.4883 - acc: 0.77 - ETA: 11s - loss: 0.4879 - acc: 0.77 - ETA: 11s - loss: 0.4883 - acc: 0.77 - ETA: 11s - loss: 0.4862 - acc: 0.77 - ETA: 10s - loss: 0.4874 - acc: 0.77 - ETA: 10s - loss: 0.4879 - acc: 0.77 - ETA: 10s - loss: 0.4853 - acc: 0.77 - ETA: 9s - loss: 0.4847 - acc: 0.7773 - ETA: 9s - loss: 0.4840 - acc: 0.777 - ETA: 9s - loss: 0.4849 - acc: 0.776 - ETA: 8s - loss: 0.4885 - acc: 0.774 - ETA: 8s - loss: 0.4885 - acc: 0.774 - ETA: 8s - loss: 0.4904 - acc: 0.773 - ETA: 7s - loss: 0.4887 - acc: 0.774 - ETA: 7s - loss: 0.4882 - acc: 0.774 - ETA: 6s - loss: 0.4865 - acc: 0.775 - ETA: 6s - loss: 0.4837 - acc: 0.777 - ETA: 6s - loss: 0.4836 - acc: 0.777 - ETA: 5s - loss: 0.4827 - acc: 0.778 - ETA: 5s - loss: 0.4831 - acc: 0.778 - ETA: 5s - loss: 0.4814 - acc: 0.779 - ETA: 4s - loss: 0.4801 - acc: 0.780 - ETA: 4s - loss: 0.4787 - acc: 0.780 - ETA: 3s - loss: 0.4782 - acc: 0.781 - ETA: 3s - loss: 0.4771 - acc: 0.781 - ETA: 3s - loss: 0.4773 - acc: 0.781 - ETA: 2s - loss: 0.4768 - acc: 0.781 - ETA: 2s - loss: 0.4758 - acc: 0.782 - ETA: 1s - loss: 0.4762 - acc: 0.781 - ETA: 1s - loss: 0.4761 - acc: 0.781 - ETA: 1s - loss: 0.4758 - acc: 0.781 - ETA: 0s - loss: 0.4753 - acc: 0.782 - ETA: 0s - loss: 0.4746 - acc: 0.782 - ETA: 0s - loss: 0.4743 - acc: 0.782 - 16s 392ms/step - loss: 0.4732 - acc: 0.7829\n",
      "Epoch 4/10\n",
      "42/41 [==============================] - ETA: 15s - loss: 0.4230 - acc: 0.81 - ETA: 15s - loss: 0.4475 - acc: 0.79 - ETA: 15s - loss: 0.4618 - acc: 0.78 - ETA: 14s - loss: 0.4717 - acc: 0.78 - ETA: 14s - loss: 0.4716 - acc: 0.78 - ETA: 14s - loss: 0.4715 - acc: 0.78 - ETA: 13s - loss: 0.4740 - acc: 0.78 - ETA: 13s - loss: 0.4667 - acc: 0.78 - ETA: 12s - loss: 0.4669 - acc: 0.78 - ETA: 12s - loss: 0.4701 - acc: 0.78 - ETA: 12s - loss: 0.4720 - acc: 0.78 - ETA: 11s - loss: 0.4701 - acc: 0.78 - ETA: 11s - loss: 0.4719 - acc: 0.78 - ETA: 10s - loss: 0.4691 - acc: 0.78 - ETA: 9s - loss: 0.4719 - acc: 0.7847 - ETA: 9s - loss: 0.4691 - acc: 0.786 - ETA: 9s - loss: 0.4699 - acc: 0.785 - ETA: 8s - loss: 0.4682 - acc: 0.786 - ETA: 8s - loss: 0.4709 - acc: 0.784 - ETA: 8s - loss: 0.4690 - acc: 0.785 - ETA: 7s - loss: 0.4679 - acc: 0.786 - ETA: 7s - loss: 0.4682 - acc: 0.786 - ETA: 7s - loss: 0.4681 - acc: 0.786 - ETA: 6s - loss: 0.4665 - acc: 0.787 - ETA: 6s - loss: 0.4656 - acc: 0.788 - ETA: 5s - loss: 0.4642 - acc: 0.789 - ETA: 5s - loss: 0.4652 - acc: 0.788 - ETA: 5s - loss: 0.4655 - acc: 0.788 - ETA: 4s - loss: 0.4643 - acc: 0.789 - ETA: 4s - loss: 0.4633 - acc: 0.789 - ETA: 3s - loss: 0.4634 - acc: 0.789 - ETA: 3s - loss: 0.4630 - acc: 0.790 - ETA: 3s - loss: 0.4642 - acc: 0.789 - ETA: 2s - loss: 0.4648 - acc: 0.789 - ETA: 2s - loss: 0.4660 - acc: 0.788 - ETA: 2s - loss: 0.4668 - acc: 0.788 - ETA: 1s - loss: 0.4680 - acc: 0.787 - ETA: 1s - loss: 0.4680 - acc: 0.787 - ETA: 0s - loss: 0.4681 - acc: 0.787 - ETA: 0s - loss: 0.4685 - acc: 0.787 - ETA: 0s - loss: 0.4677 - acc: 0.787 - 17s 395ms/step - loss: 0.4672 - acc: 0.7880\n",
      "Epoch 5/10\n",
      "42/41 [==============================] - ETA: 15s - loss: 0.4981 - acc: 0.77 - ETA: 15s - loss: 0.4637 - acc: 0.79 - ETA: 15s - loss: 0.4611 - acc: 0.79 - ETA: 14s - loss: 0.4599 - acc: 0.79 - ETA: 14s - loss: 0.4656 - acc: 0.79 - ETA: 14s - loss: 0.4553 - acc: 0.79 - ETA: 13s - loss: 0.4555 - acc: 0.79 - ETA: 13s - loss: 0.4554 - acc: 0.79 - ETA: 12s - loss: 0.4574 - acc: 0.79 - ETA: 12s - loss: 0.4492 - acc: 0.79 - ETA: 12s - loss: 0.4448 - acc: 0.80 - ETA: 11s - loss: 0.4481 - acc: 0.79 - ETA: 11s - loss: 0.4438 - acc: 0.80 - ETA: 10s - loss: 0.4454 - acc: 0.80 - ETA: 10s - loss: 0.4464 - acc: 0.79 - ETA: 10s - loss: 0.4467 - acc: 0.79 - ETA: 9s - loss: 0.4467 - acc: 0.7999 - ETA: 8s - loss: 0.4449 - acc: 0.801 - ETA: 8s - loss: 0.4461 - acc: 0.800 - ETA: 8s - loss: 0.4478 - acc: 0.798 - ETA: 7s - loss: 0.4467 - acc: 0.799 - ETA: 7s - loss: 0.4473 - acc: 0.799 - ETA: 6s - loss: 0.4472 - acc: 0.799 - ETA: 6s - loss: 0.4489 - acc: 0.798 - ETA: 6s - loss: 0.4482 - acc: 0.798 - ETA: 5s - loss: 0.4491 - acc: 0.798 - ETA: 5s - loss: 0.4496 - acc: 0.797 - ETA: 5s - loss: 0.4503 - acc: 0.796 - ETA: 4s - loss: 0.4505 - acc: 0.796 - ETA: 4s - loss: 0.4491 - acc: 0.797 - ETA: 3s - loss: 0.4506 - acc: 0.796 - ETA: 3s - loss: 0.4499 - acc: 0.796 - ETA: 3s - loss: 0.4508 - acc: 0.796 - ETA: 2s - loss: 0.4526 - acc: 0.794 - ETA: 2s - loss: 0.4529 - acc: 0.794 - ETA: 1s - loss: 0.4527 - acc: 0.795 - ETA: 1s - loss: 0.4527 - acc: 0.795 - ETA: 1s - loss: 0.4534 - acc: 0.794 - ETA: 0s - loss: 0.4535 - acc: 0.794 - ETA: 0s - loss: 0.4525 - acc: 0.795 - ETA: 0s - loss: 0.4519 - acc: 0.795 - 16s 392ms/step - loss: 0.4520 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "26/41 [=================>............] - ETA: 15s - loss: 0.4354 - acc: 0.80 - ETA: 15s - loss: 0.4470 - acc: 0.80 - ETA: 15s - loss: 0.4572 - acc: 0.79 - ETA: 14s - loss: 0.4690 - acc: 0.78 - ETA: 14s - loss: 0.4610 - acc: 0.79 - ETA: 13s - loss: 0.4639 - acc: 0.79 - ETA: 13s - loss: 0.4593 - acc: 0.79 - ETA: 13s - loss: 0.4550 - acc: 0.79 - ETA: 12s - loss: 0.4531 - acc: 0.79 - ETA: 12s - loss: 0.4566 - acc: 0.79 - ETA: 12s - loss: 0.4531 - acc: 0.79 - ETA: 11s - loss: 0.4503 - acc: 0.79 - ETA: 11s - loss: 0.4479 - acc: 0.79 - ETA: 10s - loss: 0.4453 - acc: 0.80 - ETA: 10s - loss: 0.4431 - acc: 0.80 - ETA: 10s - loss: 0.4422 - acc: 0.80 - ETA: 9s - loss: 0.4442 - acc: 0.8009 - ETA: 9s - loss: 0.4424 - acc: 0.801 - ETA: 8s - loss: 0.4415 - acc: 0.801 - ETA: 8s - loss: 0.4418 - acc: 0.800 - ETA: 8s - loss: 0.4422 - acc: 0.800 - ETA: 7s - loss: 0.4425 - acc: 0.800 - ETA: 7s - loss: 0.4431 - acc: 0.799 - ETA: 6s - loss: 0.4439 - acc: 0.799 - ETA: 6s - loss: 0.4437 - acc: 0.798 - ETA: 6s - loss: 0.4465 - acc: 0.7973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a7324580afec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n\u001b[1;32m---> 10\u001b[1;33m                     steps_per_epoch=len(X_train) / 32, epochs=10)\n\u001b[0m",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='constant'\n",
    ")\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "Epoch 1\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.13791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d87d48612690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         results = model.fit(X_train, Y_train, validation_split=0.1,\n\u001b[1;32m---> 15\u001b[1;33m                     callbacks=[checkpointer], verbose=0)\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for e in range(10):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X_train, Y_train, batch_size=32):\n",
    "        results = model.fit(X_train, Y_train, validation_split=0.1,\n",
    "                    callbacks=[checkpointer], verbose=0)\n",
    "        batches += 1\n",
    "        if batches >= len(X_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model on validation images, save to csv and get Dice metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 145/145 [00:02<00:00, 57.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 172.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice metric for valid imgs: 0.9512201277679161\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "valid_imgs = Get_IMGs('data\\\\valid\\\\') #get np.array with images\n",
    "valid_true_masks = Get_Masks('data\\\\valid_mask\\\\')#get np.array with masks\n",
    "\n",
    "valid_pred_masks = (model.predict(valid_imgs)> 0.5).astype(np.uint8) #get predicted masks\n",
    "\n",
    "# Save valid rle_masks to pred_valid_template.csv\n",
    "df = pd.DataFrame({\n",
    "        'id': [int(x.split('.')[0]) for x in next(os.walk('data\\\\valid\\\\'))[2]],\n",
    "        'rle_mask': [encode_rle(mask) for mask in np.squeeze(valid_pred_masks)]\n",
    "})\n",
    "df.to_csv('data/pred_valid_template.csv',index=False)  #save to csv\n",
    "\n",
    "#Check Dice metric\n",
    "Dice_metric = get_dice(np.squeeze(valid_true_masks), np.squeeze(valid_pred_masks))\n",
    "print('Dice metric for valid imgs:', Dice_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice metric for valid imgs: 0.951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image, true mask and predicted mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62aab4bd70f40caabbe409288061d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=145), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(valid_imgs),1))\n",
    "def g(i=0):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('image')\n",
    "    plt.imshow(valid_imgs[i,:,:])\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('true mask')\n",
    "    plt.imshow(valid_true_masks[i,:,:,0])\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('mask predicted')\n",
    "    plt.imshow(valid_pred_masks[i,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get masks from test images and create examples.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 74.56it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = Get_IMGs('data/test/') \n",
    "\n",
    "# Predict masks for test imgs\n",
    "model = load_model('model_1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "test_pred_masks = model.predict(test_imgs)\n",
    "test_pred_masks = np.squeeze(test_pred_masks > 0.5).astype(np.uint8)*255 \n",
    "# without *255 masks, putted in example.html, will look like black rectangle\n",
    "\n",
    "# Save to html\n",
    "paths_to_imgs = sorted(glob(\"data\\\\test\\\\*\"))\n",
    "_ = get_html(paths_to_imgs, test_pred_masks, path_to_save=\"results\\\\example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
