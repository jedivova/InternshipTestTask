{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "from lib import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 240\n",
    "IMG_HEIGHT = 320\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS model of U-net and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Vladimir\\Desktop\\popka\\Python\\InternshipTestTask\\human_segmentation\\lib\\utils.py:92: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:259: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:1138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:1155: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 240, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 320, 240, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 320, 240, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 320, 240, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 320, 240, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 160, 120, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 160, 120, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 160, 120, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 160, 120, 32) 9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 80, 60, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 80, 60, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 80, 60, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 80, 60, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 40, 30, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 40, 30, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 40, 30, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 40, 30, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 20, 15, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 20, 15, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20, 15, 256)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 15, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 40, 30, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40, 30, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 40, 30, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 40, 30, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 30, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 80, 60, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 80, 60, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 80, 60, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 80, 60, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_14 (Conv2D)              (None, 80, 60, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 160, 120, 32) 8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 160, 120, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 160, 120, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 160, 120, 32) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 160, 120, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 320, 240, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 320, 240, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 320, 240, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 320, 240, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 320, 240, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 320, 240, 1)  17          conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:18<00:00, 72.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1315/1315 [00:06<00:00, 208.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1183 samples, validate on 132 samples\n",
      "Epoch 1/50\n",
      "1183/1183 [==============================] - ETA: 5:15 - loss: 0.7563 - mean_iou: 0.0000e+ - ETA: 2:43 - loss: 0.7408 - mean_iou: 0.1411   - ETA: 1:53 - loss: 0.8979 - mean_iou: 0.18 - ETA: 1:28 - loss: 0.8396 - mean_iou: 0.21 - ETA: 1:13 - loss: 0.8140 - mean_iou: 0.23 - ETA: 1:03 - loss: 0.7944 - mean_iou: 0.25 - ETA: 55s - loss: 0.7809 - mean_iou: 0.2579 - ETA: 50s - loss: 0.7699 - mean_iou: 0.262 - ETA: 45s - loss: 0.7613 - mean_iou: 0.266 - ETA: 41s - loss: 0.7512 - mean_iou: 0.269 - ETA: 38s - loss: 0.7435 - mean_iou: 0.270 - ETA: 36s - loss: 0.7374 - mean_iou: 0.271 - ETA: 33s - loss: 0.7319 - mean_iou: 0.272 - ETA: 32s - loss: 0.7275 - mean_iou: 0.273 - ETA: 30s - loss: 0.7216 - mean_iou: 0.274 - ETA: 28s - loss: 0.7162 - mean_iou: 0.275 - ETA: 27s - loss: 0.7149 - mean_iou: 0.276 - ETA: 26s - loss: 0.7103 - mean_iou: 0.277 - ETA: 25s - loss: 0.7071 - mean_iou: 0.277 - ETA: 24s - loss: 0.7051 - mean_iou: 0.278 - ETA: 23s - loss: 0.7020 - mean_iou: 0.279 - ETA: 22s - loss: 0.6994 - mean_iou: 0.280 - ETA: 21s - loss: 0.6932 - mean_iou: 0.281 - ETA: 20s - loss: 0.6900 - mean_iou: 0.282 - ETA: 20s - loss: 0.6849 - mean_iou: 0.283 - ETA: 19s - loss: 0.6789 - mean_iou: 0.284 - ETA: 18s - loss: 0.6820 - mean_iou: 0.285 - ETA: 18s - loss: 0.6849 - mean_iou: 0.286 - ETA: 17s - loss: 0.6893 - mean_iou: 0.287 - ETA: 16s - loss: 0.6871 - mean_iou: 0.288 - ETA: 16s - loss: 0.6869 - mean_iou: 0.289 - ETA: 15s - loss: 0.6846 - mean_iou: 0.291 - ETA: 15s - loss: 0.6839 - mean_iou: 0.292 - ETA: 14s - loss: 0.6831 - mean_iou: 0.293 - ETA: 14s - loss: 0.6820 - mean_iou: 0.293 - ETA: 13s - loss: 0.6825 - mean_iou: 0.294 - ETA: 13s - loss: 0.6818 - mean_iou: 0.295 - ETA: 12s - loss: 0.6812 - mean_iou: 0.296 - ETA: 12s - loss: 0.6792 - mean_iou: 0.296 - ETA: 11s - loss: 0.6776 - mean_iou: 0.297 - ETA: 11s - loss: 0.6759 - mean_iou: 0.298 - ETA: 10s - loss: 0.6750 - mean_iou: 0.298 - ETA: 10s - loss: 0.6733 - mean_iou: 0.299 - ETA: 10s - loss: 0.6713 - mean_iou: 0.299 - ETA: 9s - loss: 0.6693 - mean_iou: 0.300 - ETA: 9s - loss: 0.6677 - mean_iou: 0.30 - ETA: 8s - loss: 0.6655 - mean_iou: 0.30 - ETA: 8s - loss: 0.6644 - mean_iou: 0.30 - ETA: 8s - loss: 0.6645 - mean_iou: 0.30 - ETA: 7s - loss: 0.6643 - mean_iou: 0.30 - ETA: 7s - loss: 0.6644 - mean_iou: 0.30 - ETA: 7s - loss: 0.6628 - mean_iou: 0.30 - ETA: 6s - loss: 0.6607 - mean_iou: 0.30 - ETA: 6s - loss: 0.6582 - mean_iou: 0.30 - ETA: 6s - loss: 0.6563 - mean_iou: 0.30 - ETA: 5s - loss: 0.6574 - mean_iou: 0.30 - ETA: 5s - loss: 0.6554 - mean_iou: 0.30 - ETA: 5s - loss: 0.6544 - mean_iou: 0.30 - ETA: 4s - loss: 0.6535 - mean_iou: 0.30 - ETA: 4s - loss: 0.6527 - mean_iou: 0.30 - ETA: 4s - loss: 0.6522 - mean_iou: 0.30 - ETA: 3s - loss: 0.6513 - mean_iou: 0.30 - ETA: 3s - loss: 0.6494 - mean_iou: 0.31 - ETA: 3s - loss: 0.6478 - mean_iou: 0.31 - ETA: 2s - loss: 0.6465 - mean_iou: 0.31 - ETA: 2s - loss: 0.6438 - mean_iou: 0.31 - ETA: 2s - loss: 0.6436 - mean_iou: 0.31 - ETA: 1s - loss: 0.6444 - mean_iou: 0.31 - ETA: 1s - loss: 0.6436 - mean_iou: 0.31 - ETA: 1s - loss: 0.6436 - mean_iou: 0.31 - ETA: 0s - loss: 0.6417 - mean_iou: 0.31 - ETA: 0s - loss: 0.6406 - mean_iou: 0.31 - ETA: 0s - loss: 0.6397 - mean_iou: 0.31 - 25s 21ms/step - loss: 0.6389 - mean_iou: 0.3165 - val_loss: 0.5685 - val_mean_iou: 0.3569\n",
      "Epoch 2/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.5783 - mean_iou: 0.357 - ETA: 17s - loss: 0.5664 - mean_iou: 0.357 - ETA: 17s - loss: 0.5607 - mean_iou: 0.357 - ETA: 17s - loss: 0.5534 - mean_iou: 0.357 - ETA: 17s - loss: 0.5536 - mean_iou: 0.358 - ETA: 16s - loss: 0.5628 - mean_iou: 0.358 - ETA: 16s - loss: 0.5630 - mean_iou: 0.358 - ETA: 16s - loss: 0.5500 - mean_iou: 0.359 - ETA: 16s - loss: 0.5467 - mean_iou: 0.359 - ETA: 16s - loss: 0.5445 - mean_iou: 0.359 - ETA: 15s - loss: 0.5440 - mean_iou: 0.360 - ETA: 15s - loss: 0.5418 - mean_iou: 0.360 - ETA: 15s - loss: 0.5338 - mean_iou: 0.361 - ETA: 15s - loss: 0.5353 - mean_iou: 0.361 - ETA: 14s - loss: 0.5316 - mean_iou: 0.362 - ETA: 14s - loss: 0.5300 - mean_iou: 0.363 - ETA: 14s - loss: 0.5275 - mean_iou: 0.363 - ETA: 14s - loss: 0.5318 - mean_iou: 0.364 - ETA: 13s - loss: 0.5323 - mean_iou: 0.364 - ETA: 13s - loss: 0.5295 - mean_iou: 0.365 - ETA: 13s - loss: 0.5239 - mean_iou: 0.365 - ETA: 13s - loss: 0.5228 - mean_iou: 0.366 - ETA: 12s - loss: 0.5215 - mean_iou: 0.367 - ETA: 12s - loss: 0.5232 - mean_iou: 0.367 - ETA: 12s - loss: 0.5201 - mean_iou: 0.368 - ETA: 11s - loss: 0.5180 - mean_iou: 0.368 - ETA: 11s - loss: 0.5147 - mean_iou: 0.369 - ETA: 11s - loss: 0.5123 - mean_iou: 0.370 - ETA: 11s - loss: 0.5108 - mean_iou: 0.370 - ETA: 11s - loss: 0.5102 - mean_iou: 0.371 - ETA: 10s - loss: 0.5087 - mean_iou: 0.372 - ETA: 10s - loss: 0.5061 - mean_iou: 0.372 - ETA: 10s - loss: 0.5067 - mean_iou: 0.373 - ETA: 9s - loss: 0.5066 - mean_iou: 0.373 - ETA: 9s - loss: 0.5059 - mean_iou: 0.37 - ETA: 9s - loss: 0.5059 - mean_iou: 0.37 - ETA: 9s - loss: 0.5036 - mean_iou: 0.37 - ETA: 8s - loss: 0.5028 - mean_iou: 0.37 - ETA: 8s - loss: 0.5020 - mean_iou: 0.37 - ETA: 8s - loss: 0.5035 - mean_iou: 0.37 - ETA: 8s - loss: 0.5024 - mean_iou: 0.37 - ETA: 8s - loss: 0.5026 - mean_iou: 0.37 - ETA: 7s - loss: 0.5034 - mean_iou: 0.37 - ETA: 7s - loss: 0.5018 - mean_iou: 0.38 - ETA: 7s - loss: 0.5019 - mean_iou: 0.38 - ETA: 7s - loss: 0.5032 - mean_iou: 0.38 - ETA: 6s - loss: 0.5029 - mean_iou: 0.38 - ETA: 6s - loss: 0.5028 - mean_iou: 0.38 - ETA: 6s - loss: 0.5016 - mean_iou: 0.38 - ETA: 5s - loss: 0.5003 - mean_iou: 0.38 - ETA: 5s - loss: 0.5004 - mean_iou: 0.38 - ETA: 5s - loss: 0.5013 - mean_iou: 0.38 - ETA: 5s - loss: 0.5000 - mean_iou: 0.38 - ETA: 4s - loss: 0.5002 - mean_iou: 0.38 - ETA: 4s - loss: 0.5004 - mean_iou: 0.38 - ETA: 4s - loss: 0.4986 - mean_iou: 0.38 - ETA: 4s - loss: 0.4986 - mean_iou: 0.38 - ETA: 3s - loss: 0.4986 - mean_iou: 0.38 - ETA: 3s - loss: 0.4980 - mean_iou: 0.38 - ETA: 3s - loss: 0.4978 - mean_iou: 0.38 - ETA: 3s - loss: 0.4967 - mean_iou: 0.38 - ETA: 2s - loss: 0.4964 - mean_iou: 0.38 - ETA: 2s - loss: 0.4961 - mean_iou: 0.39 - ETA: 2s - loss: 0.4946 - mean_iou: 0.39 - ETA: 2s - loss: 0.4942 - mean_iou: 0.39 - ETA: 1s - loss: 0.4930 - mean_iou: 0.39 - ETA: 1s - loss: 0.4929 - mean_iou: 0.39 - ETA: 1s - loss: 0.4922 - mean_iou: 0.39 - ETA: 1s - loss: 0.4947 - mean_iou: 0.39 - ETA: 0s - loss: 0.4948 - mean_iou: 0.39 - ETA: 0s - loss: 0.4951 - mean_iou: 0.39 - ETA: 0s - loss: 0.4948 - mean_iou: 0.39 - ETA: 0s - loss: 0.4948 - mean_iou: 0.39 - 20s 17ms/step - loss: 0.4947 - mean_iou: 0.3953 - val_loss: 0.5452 - val_mean_iou: 0.4315\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.4584 - mean_iou: 0.433 - ETA: 18s - loss: 0.4805 - mean_iou: 0.434 - ETA: 17s - loss: 0.4787 - mean_iou: 0.434 - ETA: 17s - loss: 0.4740 - mean_iou: 0.434 - ETA: 17s - loss: 0.4609 - mean_iou: 0.434 - ETA: 16s - loss: 0.4622 - mean_iou: 0.435 - ETA: 16s - loss: 0.4800 - mean_iou: 0.435 - ETA: 16s - loss: 0.4761 - mean_iou: 0.435 - ETA: 15s - loss: 0.4705 - mean_iou: 0.436 - ETA: 15s - loss: 0.4681 - mean_iou: 0.436 - ETA: 15s - loss: 0.4676 - mean_iou: 0.436 - ETA: 15s - loss: 0.4709 - mean_iou: 0.436 - ETA: 15s - loss: 0.4693 - mean_iou: 0.437 - ETA: 14s - loss: 0.4692 - mean_iou: 0.437 - ETA: 14s - loss: 0.4661 - mean_iou: 0.437 - ETA: 14s - loss: 0.4676 - mean_iou: 0.437 - ETA: 14s - loss: 0.4643 - mean_iou: 0.438 - ETA: 13s - loss: 0.4629 - mean_iou: 0.438 - ETA: 13s - loss: 0.4624 - mean_iou: 0.438 - ETA: 13s - loss: 0.4614 - mean_iou: 0.438 - ETA: 12s - loss: 0.4608 - mean_iou: 0.439 - ETA: 12s - loss: 0.4577 - mean_iou: 0.439 - ETA: 12s - loss: 0.4574 - mean_iou: 0.439 - ETA: 12s - loss: 0.4540 - mean_iou: 0.440 - ETA: 11s - loss: 0.4529 - mean_iou: 0.440 - ETA: 11s - loss: 0.4547 - mean_iou: 0.440 - ETA: 11s - loss: 0.4540 - mean_iou: 0.440 - ETA: 11s - loss: 0.4564 - mean_iou: 0.441 - ETA: 11s - loss: 0.4558 - mean_iou: 0.441 - ETA: 10s - loss: 0.4526 - mean_iou: 0.441 - ETA: 10s - loss: 0.4548 - mean_iou: 0.442 - ETA: 10s - loss: 0.4539 - mean_iou: 0.442 - ETA: 10s - loss: 0.4540 - mean_iou: 0.442 - ETA: 9s - loss: 0.4547 - mean_iou: 0.443 - ETA: 9s - loss: 0.4532 - mean_iou: 0.44 - ETA: 9s - loss: 0.4515 - mean_iou: 0.44 - ETA: 9s - loss: 0.4514 - mean_iou: 0.44 - ETA: 8s - loss: 0.4515 - mean_iou: 0.44 - ETA: 8s - loss: 0.4511 - mean_iou: 0.44 - ETA: 8s - loss: 0.4503 - mean_iou: 0.44 - ETA: 8s - loss: 0.4516 - mean_iou: 0.44 - ETA: 7s - loss: 0.4503 - mean_iou: 0.44 - ETA: 7s - loss: 0.4483 - mean_iou: 0.44 - ETA: 7s - loss: 0.4483 - mean_iou: 0.44 - ETA: 7s - loss: 0.4495 - mean_iou: 0.44 - ETA: 6s - loss: 0.4475 - mean_iou: 0.44 - ETA: 6s - loss: 0.4496 - mean_iou: 0.44 - ETA: 6s - loss: 0.4495 - mean_iou: 0.44 - ETA: 6s - loss: 0.4488 - mean_iou: 0.44 - ETA: 5s - loss: 0.4494 - mean_iou: 0.44 - ETA: 5s - loss: 0.4485 - mean_iou: 0.44 - ETA: 5s - loss: 0.4476 - mean_iou: 0.44 - ETA: 5s - loss: 0.4467 - mean_iou: 0.44 - ETA: 4s - loss: 0.4470 - mean_iou: 0.44 - ETA: 4s - loss: 0.4468 - mean_iou: 0.44 - ETA: 4s - loss: 0.4488 - mean_iou: 0.44 - ETA: 4s - loss: 0.4477 - mean_iou: 0.44 - ETA: 3s - loss: 0.4475 - mean_iou: 0.44 - ETA: 3s - loss: 0.4478 - mean_iou: 0.45 - ETA: 3s - loss: 0.4473 - mean_iou: 0.45 - ETA: 3s - loss: 0.4462 - mean_iou: 0.45 - ETA: 2s - loss: 0.4477 - mean_iou: 0.45 - ETA: 2s - loss: 0.4470 - mean_iou: 0.45 - ETA: 2s - loss: 0.4465 - mean_iou: 0.45 - ETA: 2s - loss: 0.4464 - mean_iou: 0.45 - ETA: 1s - loss: 0.4457 - mean_iou: 0.45 - ETA: 1s - loss: 0.4448 - mean_iou: 0.45 - ETA: 1s - loss: 0.4457 - mean_iou: 0.45 - ETA: 1s - loss: 0.4447 - mean_iou: 0.45 - ETA: 0s - loss: 0.4448 - mean_iou: 0.45 - ETA: 0s - loss: 0.4451 - mean_iou: 0.45 - ETA: 0s - loss: 0.4445 - mean_iou: 0.45 - ETA: 0s - loss: 0.4450 - mean_iou: 0.45 - 19s 16ms/step - loss: 0.4443 - mean_iou: 0.4541 - val_loss: 0.5653 - val_mean_iou: 0.4741\n",
      "Epoch 4/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.3804 - mean_iou: 0.475 - ETA: 19s - loss: 0.4203 - mean_iou: 0.475 - ETA: 18s - loss: 0.4158 - mean_iou: 0.476 - ETA: 18s - loss: 0.4272 - mean_iou: 0.476 - ETA: 17s - loss: 0.4104 - mean_iou: 0.476 - ETA: 17s - loss: 0.4112 - mean_iou: 0.476 - ETA: 16s - loss: 0.4132 - mean_iou: 0.477 - ETA: 16s - loss: 0.4135 - mean_iou: 0.477 - ETA: 16s - loss: 0.4140 - mean_iou: 0.477 - ETA: 15s - loss: 0.4249 - mean_iou: 0.477 - ETA: 15s - loss: 0.4213 - mean_iou: 0.478 - ETA: 15s - loss: 0.4174 - mean_iou: 0.478 - ETA: 15s - loss: 0.4189 - mean_iou: 0.478 - ETA: 14s - loss: 0.4147 - mean_iou: 0.478 - ETA: 14s - loss: 0.4118 - mean_iou: 0.478 - ETA: 14s - loss: 0.4077 - mean_iou: 0.479 - ETA: 13s - loss: 0.4050 - mean_iou: 0.479 - ETA: 13s - loss: 0.4062 - mean_iou: 0.479 - ETA: 13s - loss: 0.4145 - mean_iou: 0.479 - ETA: 13s - loss: 0.4154 - mean_iou: 0.480 - ETA: 13s - loss: 0.4127 - mean_iou: 0.480 - ETA: 12s - loss: 0.4108 - mean_iou: 0.480 - ETA: 12s - loss: 0.4136 - mean_iou: 0.480 - ETA: 12s - loss: 0.4128 - mean_iou: 0.480 - ETA: 12s - loss: 0.4151 - mean_iou: 0.481 - ETA: 11s - loss: 0.4159 - mean_iou: 0.481 - ETA: 11s - loss: 0.4154 - mean_iou: 0.481 - ETA: 11s - loss: 0.4174 - mean_iou: 0.481 - ETA: 11s - loss: 0.4172 - mean_iou: 0.481 - ETA: 10s - loss: 0.4182 - mean_iou: 0.482 - ETA: 10s - loss: 0.4211 - mean_iou: 0.482 - ETA: 10s - loss: 0.4194 - mean_iou: 0.482 - ETA: 10s - loss: 0.4193 - mean_iou: 0.482 - ETA: 9s - loss: 0.4217 - mean_iou: 0.482 - ETA: 9s - loss: 0.4194 - mean_iou: 0.48 - ETA: 9s - loss: 0.4195 - mean_iou: 0.48 - ETA: 9s - loss: 0.4179 - mean_iou: 0.48 - ETA: 8s - loss: 0.4170 - mean_iou: 0.48 - ETA: 8s - loss: 0.4156 - mean_iou: 0.48 - ETA: 8s - loss: 0.4139 - mean_iou: 0.48 - ETA: 8s - loss: 0.4140 - mean_iou: 0.48 - ETA: 7s - loss: 0.4140 - mean_iou: 0.48 - ETA: 7s - loss: 0.4129 - mean_iou: 0.48 - ETA: 7s - loss: 0.4130 - mean_iou: 0.48 - ETA: 7s - loss: 0.4121 - mean_iou: 0.48 - ETA: 6s - loss: 0.4094 - mean_iou: 0.48 - ETA: 6s - loss: 0.4095 - mean_iou: 0.48 - ETA: 6s - loss: 0.4101 - mean_iou: 0.48 - ETA: 6s - loss: 0.4090 - mean_iou: 0.48 - ETA: 5s - loss: 0.4079 - mean_iou: 0.48 - ETA: 5s - loss: 0.4086 - mean_iou: 0.48 - ETA: 5s - loss: 0.4099 - mean_iou: 0.48 - ETA: 5s - loss: 0.4104 - mean_iou: 0.48 - ETA: 4s - loss: 0.4100 - mean_iou: 0.48 - ETA: 4s - loss: 0.4098 - mean_iou: 0.48 - ETA: 4s - loss: 0.4102 - mean_iou: 0.48 - ETA: 4s - loss: 0.4110 - mean_iou: 0.48 - ETA: 3s - loss: 0.4111 - mean_iou: 0.48 - ETA: 3s - loss: 0.4109 - mean_iou: 0.48 - ETA: 3s - loss: 0.4112 - mean_iou: 0.48 - ETA: 3s - loss: 0.4113 - mean_iou: 0.48 - ETA: 2s - loss: 0.4122 - mean_iou: 0.48 - ETA: 2s - loss: 0.4122 - mean_iou: 0.48 - ETA: 2s - loss: 0.4130 - mean_iou: 0.48 - ETA: 2s - loss: 0.4124 - mean_iou: 0.48 - ETA: 1s - loss: 0.4128 - mean_iou: 0.48 - ETA: 1s - loss: 0.4131 - mean_iou: 0.48 - ETA: 1s - loss: 0.4138 - mean_iou: 0.48 - ETA: 1s - loss: 0.4135 - mean_iou: 0.48 - ETA: 0s - loss: 0.4120 - mean_iou: 0.48 - ETA: 0s - loss: 0.4118 - mean_iou: 0.48 - ETA: 0s - loss: 0.4105 - mean_iou: 0.48 - ETA: 0s - loss: 0.4101 - mean_iou: 0.49 - 19s 16ms/step - loss: 0.4100 - mean_iou: 0.4903 - val_loss: 0.5847 - val_mean_iou: 0.5041\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 19s - loss: 0.4878 - mean_iou: 0.505 - ETA: 18s - loss: 0.4174 - mean_iou: 0.505 - ETA: 17s - loss: 0.4182 - mean_iou: 0.505 - ETA: 17s - loss: 0.4104 - mean_iou: 0.506 - ETA: 17s - loss: 0.4060 - mean_iou: 0.506 - ETA: 16s - loss: 0.4083 - mean_iou: 0.506 - ETA: 16s - loss: 0.4014 - mean_iou: 0.506 - ETA: 16s - loss: 0.3990 - mean_iou: 0.506 - ETA: 16s - loss: 0.3927 - mean_iou: 0.506 - ETA: 15s - loss: 0.3909 - mean_iou: 0.506 - ETA: 15s - loss: 0.3948 - mean_iou: 0.507 - ETA: 15s - loss: 0.3928 - mean_iou: 0.507 - ETA: 15s - loss: 0.3913 - mean_iou: 0.507 - ETA: 14s - loss: 0.3928 - mean_iou: 0.507 - ETA: 14s - loss: 0.3912 - mean_iou: 0.507 - ETA: 14s - loss: 0.3900 - mean_iou: 0.507 - ETA: 14s - loss: 0.3920 - mean_iou: 0.507 - ETA: 13s - loss: 0.3945 - mean_iou: 0.508 - ETA: 13s - loss: 0.3902 - mean_iou: 0.508 - ETA: 13s - loss: 0.3947 - mean_iou: 0.508 - ETA: 13s - loss: 0.3927 - mean_iou: 0.508 - ETA: 12s - loss: 0.3901 - mean_iou: 0.508 - ETA: 12s - loss: 0.3970 - mean_iou: 0.508 - ETA: 12s - loss: 0.3955 - mean_iou: 0.509 - ETA: 12s - loss: 0.3956 - mean_iou: 0.509 - ETA: 11s - loss: 0.3963 - mean_iou: 0.509 - ETA: 11s - loss: 0.3943 - mean_iou: 0.509 - ETA: 11s - loss: 0.3939 - mean_iou: 0.509 - ETA: 11s - loss: 0.3937 - mean_iou: 0.509 - ETA: 10s - loss: 0.3940 - mean_iou: 0.509 - ETA: 10s - loss: 0.3925 - mean_iou: 0.510 - ETA: 10s - loss: 0.3925 - mean_iou: 0.510 - ETA: 10s - loss: 0.3916 - mean_iou: 0.510 - ETA: 9s - loss: 0.3928 - mean_iou: 0.510 - ETA: 9s - loss: 0.3919 - mean_iou: 0.51 - ETA: 9s - loss: 0.3917 - mean_iou: 0.51 - ETA: 9s - loss: 0.3903 - mean_iou: 0.51 - ETA: 8s - loss: 0.3913 - mean_iou: 0.51 - ETA: 8s - loss: 0.3911 - mean_iou: 0.51 - ETA: 8s - loss: 0.3925 - mean_iou: 0.51 - ETA: 8s - loss: 0.3951 - mean_iou: 0.51 - ETA: 7s - loss: 0.3966 - mean_iou: 0.51 - ETA: 7s - loss: 0.3973 - mean_iou: 0.51 - ETA: 7s - loss: 0.3967 - mean_iou: 0.51 - ETA: 7s - loss: 0.3959 - mean_iou: 0.51 - ETA: 6s - loss: 0.3957 - mean_iou: 0.51 - ETA: 6s - loss: 0.3960 - mean_iou: 0.51 - ETA: 6s - loss: 0.3962 - mean_iou: 0.51 - ETA: 6s - loss: 0.3971 - mean_iou: 0.51 - ETA: 5s - loss: 0.3961 - mean_iou: 0.51 - ETA: 5s - loss: 0.3944 - mean_iou: 0.51 - ETA: 5s - loss: 0.3939 - mean_iou: 0.51 - ETA: 5s - loss: 0.3953 - mean_iou: 0.51 - ETA: 4s - loss: 0.3953 - mean_iou: 0.51 - ETA: 4s - loss: 0.3938 - mean_iou: 0.51 - ETA: 4s - loss: 0.3931 - mean_iou: 0.51 - ETA: 4s - loss: 0.3925 - mean_iou: 0.51 - ETA: 3s - loss: 0.3921 - mean_iou: 0.51 - ETA: 3s - loss: 0.3905 - mean_iou: 0.51 - ETA: 3s - loss: 0.3894 - mean_iou: 0.51 - ETA: 3s - loss: 0.3891 - mean_iou: 0.51 - ETA: 2s - loss: 0.3900 - mean_iou: 0.51 - ETA: 2s - loss: 0.3900 - mean_iou: 0.51 - ETA: 2s - loss: 0.3894 - mean_iou: 0.51 - ETA: 2s - loss: 0.3895 - mean_iou: 0.51 - ETA: 1s - loss: 0.3911 - mean_iou: 0.51 - ETA: 1s - loss: 0.3901 - mean_iou: 0.51 - ETA: 1s - loss: 0.3891 - mean_iou: 0.51 - ETA: 1s - loss: 0.3896 - mean_iou: 0.51 - ETA: 0s - loss: 0.3891 - mean_iou: 0.51 - ETA: 0s - loss: 0.3891 - mean_iou: 0.51 - ETA: 0s - loss: 0.3881 - mean_iou: 0.51 - ETA: 0s - loss: 0.3880 - mean_iou: 0.51 - 19s 16ms/step - loss: 0.3867 - mean_iou: 0.5158 - val_loss: 0.4524 - val_mean_iou: 0.5266\n",
      "Epoch 6/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.3886 - mean_iou: 0.527 - ETA: 17s - loss: 0.4057 - mean_iou: 0.527 - ETA: 17s - loss: 0.3938 - mean_iou: 0.528 - ETA: 17s - loss: 0.4023 - mean_iou: 0.528 - ETA: 16s - loss: 0.3841 - mean_iou: 0.528 - ETA: 16s - loss: 0.3834 - mean_iou: 0.528 - ETA: 16s - loss: 0.3909 - mean_iou: 0.528 - ETA: 15s - loss: 0.3840 - mean_iou: 0.528 - ETA: 15s - loss: 0.3864 - mean_iou: 0.528 - ETA: 15s - loss: 0.3862 - mean_iou: 0.528 - ETA: 15s - loss: 0.3798 - mean_iou: 0.528 - ETA: 15s - loss: 0.3802 - mean_iou: 0.529 - ETA: 14s - loss: 0.3762 - mean_iou: 0.529 - ETA: 14s - loss: 0.3699 - mean_iou: 0.529 - ETA: 14s - loss: 0.3731 - mean_iou: 0.529 - ETA: 14s - loss: 0.3686 - mean_iou: 0.529 - ETA: 13s - loss: 0.3727 - mean_iou: 0.529 - ETA: 13s - loss: 0.3757 - mean_iou: 0.529 - ETA: 13s - loss: 0.3718 - mean_iou: 0.529 - ETA: 13s - loss: 0.3695 - mean_iou: 0.530 - ETA: 12s - loss: 0.3694 - mean_iou: 0.530 - ETA: 12s - loss: 0.3681 - mean_iou: 0.530 - ETA: 12s - loss: 0.3694 - mean_iou: 0.530 - ETA: 12s - loss: 0.3695 - mean_iou: 0.530 - ETA: 11s - loss: 0.3675 - mean_iou: 0.530 - ETA: 11s - loss: 0.3676 - mean_iou: 0.530 - ETA: 11s - loss: 0.3672 - mean_iou: 0.530 - ETA: 11s - loss: 0.3683 - mean_iou: 0.531 - ETA: 11s - loss: 0.3652 - mean_iou: 0.531 - ETA: 10s - loss: 0.3666 - mean_iou: 0.531 - ETA: 10s - loss: 0.3679 - mean_iou: 0.531 - ETA: 10s - loss: 0.3673 - mean_iou: 0.531 - ETA: 10s - loss: 0.3685 - mean_iou: 0.531 - ETA: 9s - loss: 0.3687 - mean_iou: 0.531 - ETA: 9s - loss: 0.3687 - mean_iou: 0.53 - ETA: 9s - loss: 0.3678 - mean_iou: 0.53 - ETA: 9s - loss: 0.3677 - mean_iou: 0.53 - ETA: 8s - loss: 0.3714 - mean_iou: 0.53 - ETA: 8s - loss: 0.3701 - mean_iou: 0.53 - ETA: 8s - loss: 0.3688 - mean_iou: 0.53 - ETA: 8s - loss: 0.3680 - mean_iou: 0.53 - ETA: 7s - loss: 0.3691 - mean_iou: 0.53 - ETA: 7s - loss: 0.3678 - mean_iou: 0.53 - ETA: 7s - loss: 0.3667 - mean_iou: 0.53 - ETA: 7s - loss: 0.3659 - mean_iou: 0.53 - ETA: 6s - loss: 0.3659 - mean_iou: 0.53 - ETA: 6s - loss: 0.3644 - mean_iou: 0.53 - ETA: 6s - loss: 0.3636 - mean_iou: 0.53 - ETA: 6s - loss: 0.3636 - mean_iou: 0.53 - ETA: 5s - loss: 0.3639 - mean_iou: 0.53 - ETA: 5s - loss: 0.3631 - mean_iou: 0.53 - ETA: 5s - loss: 0.3627 - mean_iou: 0.53 - ETA: 5s - loss: 0.3623 - mean_iou: 0.53 - ETA: 4s - loss: 0.3620 - mean_iou: 0.53 - ETA: 4s - loss: 0.3618 - mean_iou: 0.53 - ETA: 4s - loss: 0.3622 - mean_iou: 0.53 - ETA: 4s - loss: 0.3623 - mean_iou: 0.53 - ETA: 3s - loss: 0.3623 - mean_iou: 0.53 - ETA: 3s - loss: 0.3631 - mean_iou: 0.53 - ETA: 3s - loss: 0.3636 - mean_iou: 0.53 - ETA: 3s - loss: 0.3643 - mean_iou: 0.53 - ETA: 2s - loss: 0.3639 - mean_iou: 0.53 - ETA: 2s - loss: 0.3636 - mean_iou: 0.53 - ETA: 2s - loss: 0.3635 - mean_iou: 0.53 - ETA: 2s - loss: 0.3637 - mean_iou: 0.53 - ETA: 1s - loss: 0.3630 - mean_iou: 0.53 - ETA: 1s - loss: 0.3629 - mean_iou: 0.53 - ETA: 1s - loss: 0.3627 - mean_iou: 0.53 - ETA: 1s - loss: 0.3626 - mean_iou: 0.53 - ETA: 0s - loss: 0.3634 - mean_iou: 0.53 - ETA: 0s - loss: 0.3646 - mean_iou: 0.53 - ETA: 0s - loss: 0.3637 - mean_iou: 0.53 - ETA: 0s - loss: 0.3638 - mean_iou: 0.53 - 19s 16ms/step - loss: 0.3630 - mean_iou: 0.5363 - val_loss: 0.4643 - val_mean_iou: 0.5450\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 16s - loss: 0.3541 - mean_iou: 0.545 - ETA: 17s - loss: 0.3581 - mean_iou: 0.545 - ETA: 16s - loss: 0.3343 - mean_iou: 0.545 - ETA: 16s - loss: 0.3353 - mean_iou: 0.546 - ETA: 16s - loss: 0.3603 - mean_iou: 0.546 - ETA: 16s - loss: 0.3517 - mean_iou: 0.546 - ETA: 15s - loss: 0.3547 - mean_iou: 0.546 - ETA: 15s - loss: 0.3575 - mean_iou: 0.546 - ETA: 15s - loss: 0.3619 - mean_iou: 0.546 - ETA: 15s - loss: 0.3629 - mean_iou: 0.546 - ETA: 15s - loss: 0.3640 - mean_iou: 0.546 - ETA: 14s - loss: 0.3613 - mean_iou: 0.546 - ETA: 14s - loss: 0.3588 - mean_iou: 0.546 - ETA: 14s - loss: 0.3561 - mean_iou: 0.547 - ETA: 14s - loss: 0.3546 - mean_iou: 0.547 - ETA: 14s - loss: 0.3544 - mean_iou: 0.547 - ETA: 13s - loss: 0.3504 - mean_iou: 0.547 - ETA: 13s - loss: 0.3481 - mean_iou: 0.547 - ETA: 13s - loss: 0.3444 - mean_iou: 0.547 - ETA: 13s - loss: 0.3484 - mean_iou: 0.547 - ETA: 12s - loss: 0.3485 - mean_iou: 0.547 - ETA: 12s - loss: 0.3468 - mean_iou: 0.547 - ETA: 12s - loss: 0.3485 - mean_iou: 0.547 - ETA: 12s - loss: 0.3502 - mean_iou: 0.548 - ETA: 11s - loss: 0.3515 - mean_iou: 0.548 - ETA: 11s - loss: 0.3518 - mean_iou: 0.548 - ETA: 11s - loss: 0.3497 - mean_iou: 0.548 - ETA: 11s - loss: 0.3474 - mean_iou: 0.548 - ETA: 10s - loss: 0.3480 - mean_iou: 0.548 - ETA: 10s - loss: 0.3498 - mean_iou: 0.548 - ETA: 10s - loss: 0.3482 - mean_iou: 0.548 - ETA: 10s - loss: 0.3474 - mean_iou: 0.548 - ETA: 10s - loss: 0.3479 - mean_iou: 0.548 - ETA: 9s - loss: 0.3480 - mean_iou: 0.549 - ETA: 9s - loss: 0.3498 - mean_iou: 0.54 - ETA: 9s - loss: 0.3488 - mean_iou: 0.54 - ETA: 9s - loss: 0.3493 - mean_iou: 0.54 - ETA: 8s - loss: 0.3471 - mean_iou: 0.54 - ETA: 8s - loss: 0.3490 - mean_iou: 0.54 - ETA: 8s - loss: 0.3504 - mean_iou: 0.54 - ETA: 8s - loss: 0.3503 - mean_iou: 0.54 - ETA: 7s - loss: 0.3526 - mean_iou: 0.54 - ETA: 7s - loss: 0.3519 - mean_iou: 0.54 - ETA: 7s - loss: 0.3509 - mean_iou: 0.55 - ETA: 7s - loss: 0.3503 - mean_iou: 0.55 - ETA: 6s - loss: 0.3520 - mean_iou: 0.55 - ETA: 6s - loss: 0.3506 - mean_iou: 0.55 - ETA: 6s - loss: 0.3507 - mean_iou: 0.55 - ETA: 6s - loss: 0.3503 - mean_iou: 0.55 - ETA: 5s - loss: 0.3501 - mean_iou: 0.55 - ETA: 5s - loss: 0.3493 - mean_iou: 0.55 - ETA: 5s - loss: 0.3491 - mean_iou: 0.55 - ETA: 5s - loss: 0.3486 - mean_iou: 0.55 - ETA: 4s - loss: 0.3477 - mean_iou: 0.55 - ETA: 4s - loss: 0.3471 - mean_iou: 0.55 - ETA: 4s - loss: 0.3480 - mean_iou: 0.55 - ETA: 4s - loss: 0.3472 - mean_iou: 0.55 - ETA: 3s - loss: 0.3472 - mean_iou: 0.55 - ETA: 3s - loss: 0.3461 - mean_iou: 0.55 - ETA: 3s - loss: 0.3462 - mean_iou: 0.55 - ETA: 3s - loss: 0.3450 - mean_iou: 0.55 - ETA: 2s - loss: 0.3445 - mean_iou: 0.55 - ETA: 2s - loss: 0.3431 - mean_iou: 0.55 - ETA: 2s - loss: 0.3429 - mean_iou: 0.55 - ETA: 2s - loss: 0.3428 - mean_iou: 0.55 - ETA: 1s - loss: 0.3415 - mean_iou: 0.55 - ETA: 1s - loss: 0.3411 - mean_iou: 0.55 - ETA: 1s - loss: 0.3408 - mean_iou: 0.55 - ETA: 1s - loss: 0.3395 - mean_iou: 0.55 - ETA: 0s - loss: 0.3397 - mean_iou: 0.55 - ETA: 0s - loss: 0.3405 - mean_iou: 0.55 - ETA: 0s - loss: 0.3404 - mean_iou: 0.55 - ETA: 0s - loss: 0.3397 - mean_iou: 0.55 - 19s 16ms/step - loss: 0.3401 - mean_iou: 0.5529 - val_loss: 0.3678 - val_mean_iou: 0.5607\n",
      "Epoch 8/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.2908 - mean_iou: 0.561 - ETA: 18s - loss: 0.3137 - mean_iou: 0.561 - ETA: 17s - loss: 0.3199 - mean_iou: 0.561 - ETA: 17s - loss: 0.3209 - mean_iou: 0.561 - ETA: 17s - loss: 0.3386 - mean_iou: 0.561 - ETA: 16s - loss: 0.3224 - mean_iou: 0.561 - ETA: 16s - loss: 0.3246 - mean_iou: 0.561 - ETA: 16s - loss: 0.3216 - mean_iou: 0.561 - ETA: 16s - loss: 0.3189 - mean_iou: 0.561 - ETA: 15s - loss: 0.3240 - mean_iou: 0.562 - ETA: 15s - loss: 0.3233 - mean_iou: 0.562 - ETA: 15s - loss: 0.3196 - mean_iou: 0.562 - ETA: 15s - loss: 0.3174 - mean_iou: 0.562 - ETA: 14s - loss: 0.3201 - mean_iou: 0.562 - ETA: 14s - loss: 0.3238 - mean_iou: 0.562 - ETA: 14s - loss: 0.3236 - mean_iou: 0.562 - ETA: 13s - loss: 0.3251 - mean_iou: 0.562 - ETA: 13s - loss: 0.3286 - mean_iou: 0.562 - ETA: 13s - loss: 0.3268 - mean_iou: 0.562 - ETA: 13s - loss: 0.3242 - mean_iou: 0.563 - ETA: 12s - loss: 0.3231 - mean_iou: 0.563 - ETA: 12s - loss: 0.3221 - mean_iou: 0.563 - ETA: 12s - loss: 0.3196 - mean_iou: 0.563 - ETA: 12s - loss: 0.3211 - mean_iou: 0.563 - ETA: 12s - loss: 0.3181 - mean_iou: 0.563 - ETA: 11s - loss: 0.3178 - mean_iou: 0.563 - ETA: 11s - loss: 0.3195 - mean_iou: 0.563 - ETA: 11s - loss: 0.3196 - mean_iou: 0.563 - ETA: 10s - loss: 0.3196 - mean_iou: 0.563 - ETA: 10s - loss: 0.3182 - mean_iou: 0.563 - ETA: 10s - loss: 0.3176 - mean_iou: 0.564 - ETA: 10s - loss: 0.3186 - mean_iou: 0.564 - ETA: 10s - loss: 0.3170 - mean_iou: 0.564 - ETA: 9s - loss: 0.3158 - mean_iou: 0.564 - ETA: 9s - loss: 0.3176 - mean_iou: 0.56 - ETA: 9s - loss: 0.3183 - mean_iou: 0.56 - ETA: 9s - loss: 0.3172 - mean_iou: 0.56 - ETA: 8s - loss: 0.3206 - mean_iou: 0.56 - ETA: 8s - loss: 0.3203 - mean_iou: 0.56 - ETA: 8s - loss: 0.3200 - mean_iou: 0.56 - ETA: 8s - loss: 0.3213 - mean_iou: 0.56 - ETA: 7s - loss: 0.3212 - mean_iou: 0.56 - ETA: 7s - loss: 0.3224 - mean_iou: 0.56 - ETA: 7s - loss: 0.3215 - mean_iou: 0.56 - ETA: 7s - loss: 0.3212 - mean_iou: 0.56 - ETA: 6s - loss: 0.3194 - mean_iou: 0.56 - ETA: 6s - loss: 0.3180 - mean_iou: 0.56 - ETA: 6s - loss: 0.3166 - mean_iou: 0.56 - ETA: 6s - loss: 0.3181 - mean_iou: 0.56 - ETA: 5s - loss: 0.3200 - mean_iou: 0.56 - ETA: 5s - loss: 0.3208 - mean_iou: 0.56 - ETA: 5s - loss: 0.3189 - mean_iou: 0.56 - ETA: 5s - loss: 0.3198 - mean_iou: 0.56 - ETA: 4s - loss: 0.3188 - mean_iou: 0.56 - ETA: 4s - loss: 0.3186 - mean_iou: 0.56 - ETA: 4s - loss: 0.3183 - mean_iou: 0.56 - ETA: 4s - loss: 0.3179 - mean_iou: 0.56 - ETA: 3s - loss: 0.3173 - mean_iou: 0.56 - ETA: 3s - loss: 0.3183 - mean_iou: 0.56 - ETA: 3s - loss: 0.3184 - mean_iou: 0.56 - ETA: 3s - loss: 0.3189 - mean_iou: 0.56 - ETA: 2s - loss: 0.3186 - mean_iou: 0.56 - ETA: 2s - loss: 0.3178 - mean_iou: 0.56 - ETA: 2s - loss: 0.3184 - mean_iou: 0.56 - ETA: 2s - loss: 0.3183 - mean_iou: 0.56 - ETA: 1s - loss: 0.3178 - mean_iou: 0.56 - ETA: 1s - loss: 0.3171 - mean_iou: 0.56 - ETA: 1s - loss: 0.3162 - mean_iou: 0.56 - ETA: 1s - loss: 0.3168 - mean_iou: 0.56 - ETA: 0s - loss: 0.3170 - mean_iou: 0.56 - ETA: 0s - loss: 0.3163 - mean_iou: 0.56 - ETA: 0s - loss: 0.3158 - mean_iou: 0.56 - ETA: 0s - loss: 0.3151 - mean_iou: 0.56 - 19s 16ms/step - loss: 0.3158 - mean_iou: 0.5679 - val_loss: 0.3258 - val_mean_iou: 0.5753\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 17s - loss: 0.3980 - mean_iou: 0.576 - ETA: 17s - loss: 0.3880 - mean_iou: 0.576 - ETA: 17s - loss: 0.3538 - mean_iou: 0.576 - ETA: 17s - loss: 0.3352 - mean_iou: 0.576 - ETA: 16s - loss: 0.3179 - mean_iou: 0.576 - ETA: 16s - loss: 0.3083 - mean_iou: 0.576 - ETA: 16s - loss: 0.3011 - mean_iou: 0.576 - ETA: 15s - loss: 0.3081 - mean_iou: 0.576 - ETA: 15s - loss: 0.3031 - mean_iou: 0.576 - ETA: 15s - loss: 0.2954 - mean_iou: 0.576 - ETA: 15s - loss: 0.2917 - mean_iou: 0.577 - ETA: 15s - loss: 0.3013 - mean_iou: 0.577 - ETA: 14s - loss: 0.3001 - mean_iou: 0.577 - ETA: 14s - loss: 0.2983 - mean_iou: 0.577 - ETA: 14s - loss: 0.3014 - mean_iou: 0.577 - ETA: 14s - loss: 0.2987 - mean_iou: 0.577 - ETA: 13s - loss: 0.2979 - mean_iou: 0.577 - ETA: 13s - loss: 0.2971 - mean_iou: 0.577 - ETA: 13s - loss: 0.3003 - mean_iou: 0.577 - ETA: 13s - loss: 0.2995 - mean_iou: 0.577 - ETA: 13s - loss: 0.3000 - mean_iou: 0.577 - ETA: 12s - loss: 0.2967 - mean_iou: 0.578 - ETA: 12s - loss: 0.2980 - mean_iou: 0.578 - ETA: 12s - loss: 0.3015 - mean_iou: 0.578 - ETA: 12s - loss: 0.3002 - mean_iou: 0.578 - ETA: 11s - loss: 0.3026 - mean_iou: 0.578 - ETA: 11s - loss: 0.2998 - mean_iou: 0.578 - ETA: 11s - loss: 0.2992 - mean_iou: 0.578 - ETA: 11s - loss: 0.2967 - mean_iou: 0.578 - ETA: 10s - loss: 0.2940 - mean_iou: 0.578 - ETA: 10s - loss: 0.2929 - mean_iou: 0.578 - ETA: 10s - loss: 0.2942 - mean_iou: 0.578 - ETA: 10s - loss: 0.2942 - mean_iou: 0.579 - ETA: 9s - loss: 0.2933 - mean_iou: 0.579 - ETA: 9s - loss: 0.2949 - mean_iou: 0.57 - ETA: 9s - loss: 0.2954 - mean_iou: 0.57 - ETA: 9s - loss: 0.2969 - mean_iou: 0.57 - ETA: 8s - loss: 0.2951 - mean_iou: 0.57 - ETA: 8s - loss: 0.2983 - mean_iou: 0.57 - ETA: 8s - loss: 0.2975 - mean_iou: 0.57 - ETA: 8s - loss: 0.2986 - mean_iou: 0.57 - ETA: 7s - loss: 0.2991 - mean_iou: 0.57 - ETA: 7s - loss: 0.2987 - mean_iou: 0.57 - ETA: 7s - loss: 0.2997 - mean_iou: 0.58 - ETA: 7s - loss: 0.2996 - mean_iou: 0.58 - ETA: 6s - loss: 0.2995 - mean_iou: 0.58 - ETA: 6s - loss: 0.3008 - mean_iou: 0.58 - ETA: 6s - loss: 0.3009 - mean_iou: 0.58 - ETA: 6s - loss: 0.3017 - mean_iou: 0.58 - ETA: 5s - loss: 0.3012 - mean_iou: 0.58 - ETA: 5s - loss: 0.3014 - mean_iou: 0.58 - ETA: 5s - loss: 0.3052 - mean_iou: 0.58 - ETA: 5s - loss: 0.3051 - mean_iou: 0.58 - ETA: 4s - loss: 0.3052 - mean_iou: 0.58 - ETA: 4s - loss: 0.3066 - mean_iou: 0.58 - ETA: 4s - loss: 0.3064 - mean_iou: 0.58 - ETA: 4s - loss: 0.3067 - mean_iou: 0.58 - ETA: 3s - loss: 0.3061 - mean_iou: 0.58 - ETA: 3s - loss: 0.3061 - mean_iou: 0.58 - ETA: 3s - loss: 0.3073 - mean_iou: 0.58 - ETA: 3s - loss: 0.3070 - mean_iou: 0.58 - ETA: 2s - loss: 0.3063 - mean_iou: 0.58 - ETA: 2s - loss: 0.3064 - mean_iou: 0.58 - ETA: 2s - loss: 0.3056 - mean_iou: 0.58 - ETA: 2s - loss: 0.3057 - mean_iou: 0.58 - ETA: 1s - loss: 0.3054 - mean_iou: 0.58 - ETA: 1s - loss: 0.3051 - mean_iou: 0.58 - ETA: 1s - loss: 0.3062 - mean_iou: 0.58 - ETA: 1s - loss: 0.3060 - mean_iou: 0.58 - ETA: 0s - loss: 0.3057 - mean_iou: 0.58 - ETA: 0s - loss: 0.3057 - mean_iou: 0.58 - ETA: 0s - loss: 0.3055 - mean_iou: 0.58 - ETA: 0s - loss: 0.3060 - mean_iou: 0.58 - 19s 16ms/step - loss: 0.3051 - mean_iou: 0.5823 - val_loss: 0.4146 - val_mean_iou: 0.5884\n",
      "Epoch 10/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.2756 - mean_iou: 0.589 - ETA: 18s - loss: 0.2851 - mean_iou: 0.589 - ETA: 17s - loss: 0.2614 - mean_iou: 0.589 - ETA: 17s - loss: 0.2591 - mean_iou: 0.589 - ETA: 17s - loss: 0.2586 - mean_iou: 0.589 - ETA: 17s - loss: 0.2689 - mean_iou: 0.589 - ETA: 17s - loss: 0.2894 - mean_iou: 0.589 - ETA: 16s - loss: 0.2880 - mean_iou: 0.589 - ETA: 16s - loss: 0.2815 - mean_iou: 0.589 - ETA: 16s - loss: 0.2834 - mean_iou: 0.589 - ETA: 16s - loss: 0.2829 - mean_iou: 0.590 - ETA: 16s - loss: 0.2795 - mean_iou: 0.590 - ETA: 15s - loss: 0.2827 - mean_iou: 0.590 - ETA: 15s - loss: 0.2773 - mean_iou: 0.590 - ETA: 15s - loss: 0.2773 - mean_iou: 0.590 - ETA: 14s - loss: 0.2840 - mean_iou: 0.590 - ETA: 14s - loss: 0.2834 - mean_iou: 0.590 - ETA: 14s - loss: 0.2815 - mean_iou: 0.590 - ETA: 13s - loss: 0.2806 - mean_iou: 0.590 - ETA: 13s - loss: 0.2816 - mean_iou: 0.590 - ETA: 13s - loss: 0.2845 - mean_iou: 0.590 - ETA: 13s - loss: 0.2842 - mean_iou: 0.590 - ETA: 12s - loss: 0.2838 - mean_iou: 0.590 - ETA: 12s - loss: 0.2848 - mean_iou: 0.591 - ETA: 12s - loss: 0.2831 - mean_iou: 0.591 - ETA: 12s - loss: 0.2813 - mean_iou: 0.591 - ETA: 11s - loss: 0.2793 - mean_iou: 0.591 - ETA: 11s - loss: 0.2784 - mean_iou: 0.591 - ETA: 11s - loss: 0.2800 - mean_iou: 0.591 - ETA: 11s - loss: 0.2817 - mean_iou: 0.591 - ETA: 10s - loss: 0.2812 - mean_iou: 0.591 - ETA: 10s - loss: 0.2793 - mean_iou: 0.591 - ETA: 10s - loss: 0.2788 - mean_iou: 0.591 - ETA: 10s - loss: 0.2804 - mean_iou: 0.591 - ETA: 9s - loss: 0.2819 - mean_iou: 0.591 - ETA: 9s - loss: 0.2798 - mean_iou: 0.59 - ETA: 9s - loss: 0.2807 - mean_iou: 0.59 - ETA: 9s - loss: 0.2802 - mean_iou: 0.59 - ETA: 8s - loss: 0.2808 - mean_iou: 0.59 - ETA: 8s - loss: 0.2799 - mean_iou: 0.59 - ETA: 8s - loss: 0.2787 - mean_iou: 0.59 - ETA: 8s - loss: 0.2798 - mean_iou: 0.59 - ETA: 7s - loss: 0.2798 - mean_iou: 0.59 - ETA: 7s - loss: 0.2787 - mean_iou: 0.59 - ETA: 7s - loss: 0.2802 - mean_iou: 0.59 - ETA: 6s - loss: 0.2794 - mean_iou: 0.59 - ETA: 6s - loss: 0.2794 - mean_iou: 0.59 - ETA: 6s - loss: 0.2783 - mean_iou: 0.59 - ETA: 6s - loss: 0.2785 - mean_iou: 0.59 - ETA: 6s - loss: 0.2782 - mean_iou: 0.59 - ETA: 5s - loss: 0.2785 - mean_iou: 0.59 - ETA: 5s - loss: 0.2798 - mean_iou: 0.59 - ETA: 5s - loss: 0.2794 - mean_iou: 0.59 - ETA: 4s - loss: 0.2799 - mean_iou: 0.59 - ETA: 4s - loss: 0.2797 - mean_iou: 0.59 - ETA: 4s - loss: 0.2795 - mean_iou: 0.59 - ETA: 4s - loss: 0.2791 - mean_iou: 0.59 - ETA: 3s - loss: 0.2785 - mean_iou: 0.59 - ETA: 3s - loss: 0.2775 - mean_iou: 0.59 - ETA: 3s - loss: 0.2782 - mean_iou: 0.59 - ETA: 3s - loss: 0.2781 - mean_iou: 0.59 - ETA: 2s - loss: 0.2794 - mean_iou: 0.59 - ETA: 2s - loss: 0.2793 - mean_iou: 0.59 - ETA: 2s - loss: 0.2804 - mean_iou: 0.59 - ETA: 2s - loss: 0.2803 - mean_iou: 0.59 - ETA: 1s - loss: 0.2803 - mean_iou: 0.59 - ETA: 1s - loss: 0.2826 - mean_iou: 0.59 - ETA: 1s - loss: 0.2831 - mean_iou: 0.59 - ETA: 1s - loss: 0.2837 - mean_iou: 0.59 - ETA: 0s - loss: 0.2834 - mean_iou: 0.59 - ETA: 0s - loss: 0.2831 - mean_iou: 0.59 - ETA: 0s - loss: 0.2839 - mean_iou: 0.59 - ETA: 0s - loss: 0.2834 - mean_iou: 0.59 - 19s 16ms/step - loss: 0.2833 - mean_iou: 0.5948 - val_loss: 0.3769 - val_mean_iou: 0.6006\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 16s - loss: 0.2741 - mean_iou: 0.601 - ETA: 16s - loss: 0.2986 - mean_iou: 0.601 - ETA: 16s - loss: 0.2961 - mean_iou: 0.601 - ETA: 16s - loss: 0.2724 - mean_iou: 0.601 - ETA: 16s - loss: 0.2565 - mean_iou: 0.601 - ETA: 16s - loss: 0.2580 - mean_iou: 0.601 - ETA: 16s - loss: 0.2560 - mean_iou: 0.601 - ETA: 15s - loss: 0.2513 - mean_iou: 0.601 - ETA: 15s - loss: 0.2522 - mean_iou: 0.601 - ETA: 15s - loss: 0.2480 - mean_iou: 0.602 - ETA: 15s - loss: 0.2510 - mean_iou: 0.602 - ETA: 15s - loss: 0.2484 - mean_iou: 0.602 - ETA: 14s - loss: 0.2537 - mean_iou: 0.602 - ETA: 14s - loss: 0.2577 - mean_iou: 0.602 - ETA: 14s - loss: 0.2560 - mean_iou: 0.602 - ETA: 14s - loss: 0.2543 - mean_iou: 0.602 - ETA: 13s - loss: 0.2553 - mean_iou: 0.602 - ETA: 13s - loss: 0.2545 - mean_iou: 0.602 - ETA: 13s - loss: 0.2534 - mean_iou: 0.602 - ETA: 13s - loss: 0.2559 - mean_iou: 0.602 - ETA: 13s - loss: 0.2575 - mean_iou: 0.602 - ETA: 12s - loss: 0.2543 - mean_iou: 0.603 - ETA: 12s - loss: 0.2545 - mean_iou: 0.603 - ETA: 12s - loss: 0.2549 - mean_iou: 0.603 - ETA: 12s - loss: 0.2551 - mean_iou: 0.603 - ETA: 11s - loss: 0.2579 - mean_iou: 0.603 - ETA: 11s - loss: 0.2563 - mean_iou: 0.603 - ETA: 11s - loss: 0.2556 - mean_iou: 0.603 - ETA: 10s - loss: 0.2553 - mean_iou: 0.603 - ETA: 10s - loss: 0.2529 - mean_iou: 0.603 - ETA: 10s - loss: 0.2559 - mean_iou: 0.603 - ETA: 10s - loss: 0.2553 - mean_iou: 0.603 - ETA: 10s - loss: 0.2574 - mean_iou: 0.603 - ETA: 9s - loss: 0.2586 - mean_iou: 0.603 - ETA: 9s - loss: 0.2585 - mean_iou: 0.60 - ETA: 9s - loss: 0.2580 - mean_iou: 0.60 - ETA: 9s - loss: 0.2571 - mean_iou: 0.60 - ETA: 8s - loss: 0.2573 - mean_iou: 0.60 - ETA: 8s - loss: 0.2553 - mean_iou: 0.60 - ETA: 8s - loss: 0.2546 - mean_iou: 0.60 - ETA: 8s - loss: 0.2547 - mean_iou: 0.60 - ETA: 7s - loss: 0.2551 - mean_iou: 0.60 - ETA: 7s - loss: 0.2555 - mean_iou: 0.60 - ETA: 7s - loss: 0.2545 - mean_iou: 0.60 - ETA: 7s - loss: 0.2560 - mean_iou: 0.60 - ETA: 6s - loss: 0.2562 - mean_iou: 0.60 - ETA: 6s - loss: 0.2570 - mean_iou: 0.60 - ETA: 6s - loss: 0.2565 - mean_iou: 0.60 - ETA: 6s - loss: 0.2556 - mean_iou: 0.60 - ETA: 5s - loss: 0.2560 - mean_iou: 0.60 - ETA: 5s - loss: 0.2557 - mean_iou: 0.60 - ETA: 5s - loss: 0.2549 - mean_iou: 0.60 - ETA: 5s - loss: 0.2539 - mean_iou: 0.60 - ETA: 4s - loss: 0.2543 - mean_iou: 0.60 - ETA: 4s - loss: 0.2538 - mean_iou: 0.60 - ETA: 4s - loss: 0.2532 - mean_iou: 0.60 - ETA: 4s - loss: 0.2531 - mean_iou: 0.60 - ETA: 3s - loss: 0.2533 - mean_iou: 0.60 - ETA: 3s - loss: 0.2532 - mean_iou: 0.60 - ETA: 3s - loss: 0.2530 - mean_iou: 0.60 - ETA: 3s - loss: 0.2532 - mean_iou: 0.60 - ETA: 2s - loss: 0.2530 - mean_iou: 0.60 - ETA: 2s - loss: 0.2535 - mean_iou: 0.60 - ETA: 2s - loss: 0.2525 - mean_iou: 0.60 - ETA: 2s - loss: 0.2525 - mean_iou: 0.60 - ETA: 1s - loss: 0.2523 - mean_iou: 0.60 - ETA: 1s - loss: 0.2519 - mean_iou: 0.60 - ETA: 1s - loss: 0.2514 - mean_iou: 0.60 - ETA: 1s - loss: 0.2520 - mean_iou: 0.60 - ETA: 0s - loss: 0.2524 - mean_iou: 0.60 - ETA: 0s - loss: 0.2525 - mean_iou: 0.60 - ETA: 0s - loss: 0.2523 - mean_iou: 0.60 - ETA: 0s - loss: 0.2522 - mean_iou: 0.60 - 19s 16ms/step - loss: 0.2532 - mean_iou: 0.6070 - val_loss: 0.3992 - val_mean_iou: 0.6131\n",
      "Epoch 12/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.2220 - mean_iou: 0.613 - ETA: 17s - loss: 0.2309 - mean_iou: 0.613 - ETA: 16s - loss: 0.2352 - mean_iou: 0.613 - ETA: 16s - loss: 0.2282 - mean_iou: 0.613 - ETA: 16s - loss: 0.2294 - mean_iou: 0.614 - ETA: 16s - loss: 0.2265 - mean_iou: 0.614 - ETA: 16s - loss: 0.2396 - mean_iou: 0.614 - ETA: 16s - loss: 0.2465 - mean_iou: 0.614 - ETA: 15s - loss: 0.2504 - mean_iou: 0.614 - ETA: 15s - loss: 0.2562 - mean_iou: 0.614 - ETA: 15s - loss: 0.2533 - mean_iou: 0.614 - ETA: 15s - loss: 0.2530 - mean_iou: 0.614 - ETA: 14s - loss: 0.2535 - mean_iou: 0.614 - ETA: 14s - loss: 0.2540 - mean_iou: 0.614 - ETA: 14s - loss: 0.2488 - mean_iou: 0.614 - ETA: 14s - loss: 0.2476 - mean_iou: 0.614 - ETA: 14s - loss: 0.2474 - mean_iou: 0.614 - ETA: 13s - loss: 0.2431 - mean_iou: 0.614 - ETA: 13s - loss: 0.2397 - mean_iou: 0.614 - ETA: 13s - loss: 0.2401 - mean_iou: 0.614 - ETA: 13s - loss: 0.2431 - mean_iou: 0.615 - ETA: 12s - loss: 0.2437 - mean_iou: 0.615 - ETA: 12s - loss: 0.2427 - mean_iou: 0.615 - ETA: 12s - loss: 0.2417 - mean_iou: 0.615 - ETA: 12s - loss: 0.2425 - mean_iou: 0.615 - ETA: 11s - loss: 0.2436 - mean_iou: 0.615 - ETA: 11s - loss: 0.2422 - mean_iou: 0.615 - ETA: 11s - loss: 0.2421 - mean_iou: 0.615 - ETA: 11s - loss: 0.2395 - mean_iou: 0.615 - ETA: 10s - loss: 0.2391 - mean_iou: 0.615 - ETA: 10s - loss: 0.2386 - mean_iou: 0.615 - ETA: 10s - loss: 0.2405 - mean_iou: 0.615 - ETA: 10s - loss: 0.2404 - mean_iou: 0.615 - ETA: 9s - loss: 0.2389 - mean_iou: 0.616 - ETA: 9s - loss: 0.2385 - mean_iou: 0.61 - ETA: 9s - loss: 0.2402 - mean_iou: 0.61 - ETA: 9s - loss: 0.2394 - mean_iou: 0.61 - ETA: 8s - loss: 0.2391 - mean_iou: 0.61 - ETA: 8s - loss: 0.2396 - mean_iou: 0.61 - ETA: 8s - loss: 0.2410 - mean_iou: 0.61 - ETA: 8s - loss: 0.2411 - mean_iou: 0.61 - ETA: 7s - loss: 0.2406 - mean_iou: 0.61 - ETA: 7s - loss: 0.2395 - mean_iou: 0.61 - ETA: 7s - loss: 0.2388 - mean_iou: 0.61 - ETA: 7s - loss: 0.2380 - mean_iou: 0.61 - ETA: 6s - loss: 0.2381 - mean_iou: 0.61 - ETA: 6s - loss: 0.2376 - mean_iou: 0.61 - ETA: 6s - loss: 0.2397 - mean_iou: 0.61 - ETA: 6s - loss: 0.2400 - mean_iou: 0.61 - ETA: 5s - loss: 0.2398 - mean_iou: 0.61 - ETA: 5s - loss: 0.2387 - mean_iou: 0.61 - ETA: 5s - loss: 0.2377 - mean_iou: 0.61 - ETA: 5s - loss: 0.2368 - mean_iou: 0.61 - ETA: 4s - loss: 0.2366 - mean_iou: 0.61 - ETA: 4s - loss: 0.2361 - mean_iou: 0.61 - ETA: 4s - loss: 0.2376 - mean_iou: 0.61 - ETA: 4s - loss: 0.2377 - mean_iou: 0.61 - ETA: 3s - loss: 0.2374 - mean_iou: 0.61 - ETA: 3s - loss: 0.2370 - mean_iou: 0.61 - ETA: 3s - loss: 0.2368 - mean_iou: 0.61 - ETA: 3s - loss: 0.2365 - mean_iou: 0.61 - ETA: 2s - loss: 0.2357 - mean_iou: 0.61 - ETA: 2s - loss: 0.2351 - mean_iou: 0.61 - ETA: 2s - loss: 0.2341 - mean_iou: 0.61 - ETA: 2s - loss: 0.2346 - mean_iou: 0.61 - ETA: 1s - loss: 0.2356 - mean_iou: 0.61 - ETA: 1s - loss: 0.2345 - mean_iou: 0.61 - ETA: 1s - loss: 0.2342 - mean_iou: 0.61 - ETA: 1s - loss: 0.2346 - mean_iou: 0.61 - ETA: 0s - loss: 0.2350 - mean_iou: 0.61 - ETA: 0s - loss: 0.2342 - mean_iou: 0.61 - ETA: 0s - loss: 0.2337 - mean_iou: 0.61 - ETA: 0s - loss: 0.2335 - mean_iou: 0.61 - 19s 16ms/step - loss: 0.2342 - mean_iou: 0.6189 - val_loss: 0.2716 - val_mean_iou: 0.6249\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1921 - mean_iou: 0.625 - ETA: 18s - loss: 0.1959 - mean_iou: 0.625 - ETA: 18s - loss: 0.2013 - mean_iou: 0.625 - ETA: 17s - loss: 0.2020 - mean_iou: 0.625 - ETA: 17s - loss: 0.2147 - mean_iou: 0.625 - ETA: 17s - loss: 0.2152 - mean_iou: 0.625 - ETA: 17s - loss: 0.2169 - mean_iou: 0.625 - ETA: 16s - loss: 0.2194 - mean_iou: 0.626 - ETA: 16s - loss: 0.2226 - mean_iou: 0.626 - ETA: 16s - loss: 0.2155 - mean_iou: 0.626 - ETA: 16s - loss: 0.2380 - mean_iou: 0.626 - ETA: 15s - loss: 0.2308 - mean_iou: 0.626 - ETA: 15s - loss: 0.2275 - mean_iou: 0.626 - ETA: 15s - loss: 0.2257 - mean_iou: 0.626 - ETA: 14s - loss: 0.2286 - mean_iou: 0.626 - ETA: 14s - loss: 0.2331 - mean_iou: 0.626 - ETA: 14s - loss: 0.2315 - mean_iou: 0.626 - ETA: 14s - loss: 0.2294 - mean_iou: 0.626 - ETA: 13s - loss: 0.2284 - mean_iou: 0.626 - ETA: 13s - loss: 0.2266 - mean_iou: 0.626 - ETA: 13s - loss: 0.2270 - mean_iou: 0.626 - ETA: 13s - loss: 0.2277 - mean_iou: 0.626 - ETA: 12s - loss: 0.2297 - mean_iou: 0.626 - ETA: 12s - loss: 0.2292 - mean_iou: 0.627 - ETA: 12s - loss: 0.2272 - mean_iou: 0.627 - ETA: 12s - loss: 0.2254 - mean_iou: 0.627 - ETA: 11s - loss: 0.2257 - mean_iou: 0.627 - ETA: 11s - loss: 0.2264 - mean_iou: 0.627 - ETA: 11s - loss: 0.2262 - mean_iou: 0.627 - ETA: 11s - loss: 0.2243 - mean_iou: 0.627 - ETA: 10s - loss: 0.2222 - mean_iou: 0.627 - ETA: 10s - loss: 0.2226 - mean_iou: 0.627 - ETA: 10s - loss: 0.2230 - mean_iou: 0.627 - ETA: 9s - loss: 0.2228 - mean_iou: 0.627 - ETA: 9s - loss: 0.2224 - mean_iou: 0.62 - ETA: 9s - loss: 0.2219 - mean_iou: 0.62 - ETA: 9s - loss: 0.2206 - mean_iou: 0.62 - ETA: 8s - loss: 0.2211 - mean_iou: 0.62 - ETA: 8s - loss: 0.2206 - mean_iou: 0.62 - ETA: 8s - loss: 0.2198 - mean_iou: 0.62 - ETA: 8s - loss: 0.2205 - mean_iou: 0.62 - ETA: 7s - loss: 0.2210 - mean_iou: 0.62 - ETA: 7s - loss: 0.2208 - mean_iou: 0.62 - ETA: 7s - loss: 0.2208 - mean_iou: 0.62 - ETA: 7s - loss: 0.2200 - mean_iou: 0.62 - ETA: 6s - loss: 0.2213 - mean_iou: 0.62 - ETA: 6s - loss: 0.2205 - mean_iou: 0.62 - ETA: 6s - loss: 0.2207 - mean_iou: 0.62 - ETA: 6s - loss: 0.2209 - mean_iou: 0.62 - ETA: 5s - loss: 0.2194 - mean_iou: 0.62 - ETA: 5s - loss: 0.2198 - mean_iou: 0.62 - ETA: 5s - loss: 0.2198 - mean_iou: 0.62 - ETA: 5s - loss: 0.2197 - mean_iou: 0.62 - ETA: 4s - loss: 0.2199 - mean_iou: 0.62 - ETA: 4s - loss: 0.2204 - mean_iou: 0.62 - ETA: 4s - loss: 0.2195 - mean_iou: 0.62 - ETA: 4s - loss: 0.2198 - mean_iou: 0.62 - ETA: 3s - loss: 0.2203 - mean_iou: 0.62 - ETA: 3s - loss: 0.2196 - mean_iou: 0.62 - ETA: 3s - loss: 0.2190 - mean_iou: 0.62 - ETA: 3s - loss: 0.2193 - mean_iou: 0.62 - ETA: 2s - loss: 0.2189 - mean_iou: 0.62 - ETA: 2s - loss: 0.2193 - mean_iou: 0.62 - ETA: 2s - loss: 0.2195 - mean_iou: 0.62 - ETA: 2s - loss: 0.2188 - mean_iou: 0.62 - ETA: 1s - loss: 0.2193 - mean_iou: 0.62 - ETA: 1s - loss: 0.2191 - mean_iou: 0.62 - ETA: 1s - loss: 0.2194 - mean_iou: 0.63 - ETA: 1s - loss: 0.2187 - mean_iou: 0.63 - ETA: 0s - loss: 0.2203 - mean_iou: 0.63 - ETA: 0s - loss: 0.2212 - mean_iou: 0.63 - ETA: 0s - loss: 0.2211 - mean_iou: 0.63 - ETA: 0s - loss: 0.2219 - mean_iou: 0.63 - 20s 17ms/step - loss: 0.2218 - mean_iou: 0.6304 - val_loss: 0.2740 - val_mean_iou: 0.6357\n",
      "Epoch 14/50\n",
      "1183/1183 [==============================] - ETA: 16s - loss: 0.2760 - mean_iou: 0.636 - ETA: 16s - loss: 0.2280 - mean_iou: 0.636 - ETA: 16s - loss: 0.2108 - mean_iou: 0.636 - ETA: 16s - loss: 0.2379 - mean_iou: 0.636 - ETA: 16s - loss: 0.2408 - mean_iou: 0.636 - ETA: 16s - loss: 0.2306 - mean_iou: 0.636 - ETA: 16s - loss: 0.2304 - mean_iou: 0.636 - ETA: 16s - loss: 0.2290 - mean_iou: 0.636 - ETA: 15s - loss: 0.2290 - mean_iou: 0.636 - ETA: 15s - loss: 0.2242 - mean_iou: 0.636 - ETA: 15s - loss: 0.2193 - mean_iou: 0.636 - ETA: 14s - loss: 0.2301 - mean_iou: 0.636 - ETA: 14s - loss: 0.2306 - mean_iou: 0.636 - ETA: 14s - loss: 0.2311 - mean_iou: 0.636 - ETA: 14s - loss: 0.2322 - mean_iou: 0.636 - ETA: 14s - loss: 0.2317 - mean_iou: 0.636 - ETA: 13s - loss: 0.2274 - mean_iou: 0.637 - ETA: 13s - loss: 0.2320 - mean_iou: 0.637 - ETA: 13s - loss: 0.2283 - mean_iou: 0.637 - ETA: 13s - loss: 0.2281 - mean_iou: 0.637 - ETA: 12s - loss: 0.2261 - mean_iou: 0.637 - ETA: 12s - loss: 0.2226 - mean_iou: 0.637 - ETA: 12s - loss: 0.2192 - mean_iou: 0.637 - ETA: 12s - loss: 0.2167 - mean_iou: 0.637 - ETA: 11s - loss: 0.2180 - mean_iou: 0.637 - ETA: 11s - loss: 0.2196 - mean_iou: 0.637 - ETA: 11s - loss: 0.2207 - mean_iou: 0.637 - ETA: 11s - loss: 0.2202 - mean_iou: 0.637 - ETA: 10s - loss: 0.2179 - mean_iou: 0.637 - ETA: 10s - loss: 0.2195 - mean_iou: 0.637 - ETA: 10s - loss: 0.2172 - mean_iou: 0.637 - ETA: 10s - loss: 0.2169 - mean_iou: 0.637 - ETA: 9s - loss: 0.2164 - mean_iou: 0.637 - ETA: 9s - loss: 0.2154 - mean_iou: 0.63 - ETA: 9s - loss: 0.2155 - mean_iou: 0.63 - ETA: 9s - loss: 0.2147 - mean_iou: 0.63 - ETA: 8s - loss: 0.2143 - mean_iou: 0.63 - ETA: 8s - loss: 0.2164 - mean_iou: 0.63 - ETA: 8s - loss: 0.2151 - mean_iou: 0.63 - ETA: 8s - loss: 0.2138 - mean_iou: 0.63 - ETA: 8s - loss: 0.2136 - mean_iou: 0.63 - ETA: 7s - loss: 0.2134 - mean_iou: 0.63 - ETA: 7s - loss: 0.2127 - mean_iou: 0.63 - ETA: 7s - loss: 0.2137 - mean_iou: 0.63 - ETA: 7s - loss: 0.2146 - mean_iou: 0.63 - ETA: 6s - loss: 0.2165 - mean_iou: 0.63 - ETA: 6s - loss: 0.2176 - mean_iou: 0.63 - ETA: 6s - loss: 0.2167 - mean_iou: 0.63 - ETA: 6s - loss: 0.2168 - mean_iou: 0.63 - ETA: 5s - loss: 0.2162 - mean_iou: 0.63 - ETA: 5s - loss: 0.2174 - mean_iou: 0.63 - ETA: 5s - loss: 0.2173 - mean_iou: 0.63 - ETA: 5s - loss: 0.2176 - mean_iou: 0.63 - ETA: 4s - loss: 0.2179 - mean_iou: 0.63 - ETA: 4s - loss: 0.2167 - mean_iou: 0.63 - ETA: 4s - loss: 0.2167 - mean_iou: 0.63 - ETA: 4s - loss: 0.2166 - mean_iou: 0.63 - ETA: 3s - loss: 0.2180 - mean_iou: 0.63 - ETA: 3s - loss: 0.2181 - mean_iou: 0.63 - ETA: 3s - loss: 0.2183 - mean_iou: 0.63 - ETA: 3s - loss: 0.2182 - mean_iou: 0.63 - ETA: 2s - loss: 0.2182 - mean_iou: 0.63 - ETA: 2s - loss: 0.2181 - mean_iou: 0.63 - ETA: 2s - loss: 0.2179 - mean_iou: 0.63 - ETA: 2s - loss: 0.2168 - mean_iou: 0.63 - ETA: 1s - loss: 0.2168 - mean_iou: 0.64 - ETA: 1s - loss: 0.2161 - mean_iou: 0.64 - ETA: 1s - loss: 0.2164 - mean_iou: 0.64 - ETA: 1s - loss: 0.2157 - mean_iou: 0.64 - ETA: 0s - loss: 0.2154 - mean_iou: 0.64 - ETA: 0s - loss: 0.2148 - mean_iou: 0.64 - ETA: 0s - loss: 0.2140 - mean_iou: 0.64 - ETA: 0s - loss: 0.2150 - mean_iou: 0.64 - 19s 16ms/step - loss: 0.2142 - mean_iou: 0.6405 - val_loss: 0.2473 - val_mean_iou: 0.6454\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1855 - mean_iou: 0.645 - ETA: 18s - loss: 0.1917 - mean_iou: 0.645 - ETA: 18s - loss: 0.1965 - mean_iou: 0.646 - ETA: 17s - loss: 0.1982 - mean_iou: 0.646 - ETA: 17s - loss: 0.2036 - mean_iou: 0.646 - ETA: 16s - loss: 0.1968 - mean_iou: 0.646 - ETA: 16s - loss: 0.1948 - mean_iou: 0.646 - ETA: 16s - loss: 0.1921 - mean_iou: 0.646 - ETA: 16s - loss: 0.1900 - mean_iou: 0.646 - ETA: 16s - loss: 0.1966 - mean_iou: 0.646 - ETA: 15s - loss: 0.1945 - mean_iou: 0.646 - ETA: 15s - loss: 0.1931 - mean_iou: 0.646 - ETA: 15s - loss: 0.1905 - mean_iou: 0.646 - ETA: 15s - loss: 0.1916 - mean_iou: 0.646 - ETA: 14s - loss: 0.1924 - mean_iou: 0.646 - ETA: 14s - loss: 0.1952 - mean_iou: 0.646 - ETA: 14s - loss: 0.1947 - mean_iou: 0.646 - ETA: 13s - loss: 0.1936 - mean_iou: 0.646 - ETA: 13s - loss: 0.1951 - mean_iou: 0.647 - ETA: 13s - loss: 0.1968 - mean_iou: 0.647 - ETA: 12s - loss: 0.1965 - mean_iou: 0.647 - ETA: 12s - loss: 0.1978 - mean_iou: 0.647 - ETA: 12s - loss: 0.1992 - mean_iou: 0.647 - ETA: 12s - loss: 0.2010 - mean_iou: 0.647 - ETA: 12s - loss: 0.1996 - mean_iou: 0.647 - ETA: 11s - loss: 0.1987 - mean_iou: 0.647 - ETA: 11s - loss: 0.1987 - mean_iou: 0.647 - ETA: 11s - loss: 0.1970 - mean_iou: 0.647 - ETA: 11s - loss: 0.1987 - mean_iou: 0.647 - ETA: 10s - loss: 0.1972 - mean_iou: 0.647 - ETA: 10s - loss: 0.1990 - mean_iou: 0.647 - ETA: 10s - loss: 0.1978 - mean_iou: 0.647 - ETA: 10s - loss: 0.1978 - mean_iou: 0.647 - ETA: 9s - loss: 0.1958 - mean_iou: 0.647 - ETA: 9s - loss: 0.1965 - mean_iou: 0.64 - ETA: 9s - loss: 0.1951 - mean_iou: 0.64 - ETA: 9s - loss: 0.1954 - mean_iou: 0.64 - ETA: 8s - loss: 0.1942 - mean_iou: 0.64 - ETA: 8s - loss: 0.1925 - mean_iou: 0.64 - ETA: 8s - loss: 0.1930 - mean_iou: 0.64 - ETA: 8s - loss: 0.1923 - mean_iou: 0.64 - ETA: 7s - loss: 0.1925 - mean_iou: 0.64 - ETA: 7s - loss: 0.1922 - mean_iou: 0.64 - ETA: 7s - loss: 0.1926 - mean_iou: 0.64 - ETA: 7s - loss: 0.1926 - mean_iou: 0.64 - ETA: 6s - loss: 0.1910 - mean_iou: 0.64 - ETA: 6s - loss: 0.1921 - mean_iou: 0.64 - ETA: 6s - loss: 0.1926 - mean_iou: 0.64 - ETA: 6s - loss: 0.1930 - mean_iou: 0.64 - ETA: 5s - loss: 0.1932 - mean_iou: 0.64 - ETA: 5s - loss: 0.1934 - mean_iou: 0.64 - ETA: 5s - loss: 0.1942 - mean_iou: 0.64 - ETA: 5s - loss: 0.1936 - mean_iou: 0.64 - ETA: 4s - loss: 0.1942 - mean_iou: 0.64 - ETA: 4s - loss: 0.1935 - mean_iou: 0.64 - ETA: 4s - loss: 0.1928 - mean_iou: 0.64 - ETA: 4s - loss: 0.1922 - mean_iou: 0.64 - ETA: 3s - loss: 0.1919 - mean_iou: 0.64 - ETA: 3s - loss: 0.1922 - mean_iou: 0.64 - ETA: 3s - loss: 0.1923 - mean_iou: 0.64 - ETA: 3s - loss: 0.1922 - mean_iou: 0.64 - ETA: 2s - loss: 0.1934 - mean_iou: 0.64 - ETA: 2s - loss: 0.1935 - mean_iou: 0.64 - ETA: 2s - loss: 0.1929 - mean_iou: 0.64 - ETA: 2s - loss: 0.1930 - mean_iou: 0.64 - ETA: 1s - loss: 0.1933 - mean_iou: 0.64 - ETA: 1s - loss: 0.1924 - mean_iou: 0.64 - ETA: 1s - loss: 0.1932 - mean_iou: 0.64 - ETA: 1s - loss: 0.1933 - mean_iou: 0.65 - ETA: 0s - loss: 0.1931 - mean_iou: 0.65 - ETA: 0s - loss: 0.1925 - mean_iou: 0.65 - ETA: 0s - loss: 0.1923 - mean_iou: 0.65 - ETA: 0s - loss: 0.1923 - mean_iou: 0.65 - 19s 16ms/step - loss: 0.1927 - mean_iou: 0.6503 - val_loss: 0.2433 - val_mean_iou: 0.6551\n",
      "Epoch 16/50\n",
      "1183/1183 [==============================] - ETA: 17s - loss: 0.1917 - mean_iou: 0.655 - ETA: 16s - loss: 0.1714 - mean_iou: 0.655 - ETA: 16s - loss: 0.1908 - mean_iou: 0.655 - ETA: 16s - loss: 0.1770 - mean_iou: 0.655 - ETA: 16s - loss: 0.1877 - mean_iou: 0.655 - ETA: 16s - loss: 0.1820 - mean_iou: 0.655 - ETA: 16s - loss: 0.1836 - mean_iou: 0.656 - ETA: 16s - loss: 0.1867 - mean_iou: 0.656 - ETA: 15s - loss: 0.1872 - mean_iou: 0.656 - ETA: 15s - loss: 0.1876 - mean_iou: 0.656 - ETA: 15s - loss: 0.1871 - mean_iou: 0.656 - ETA: 14s - loss: 0.1839 - mean_iou: 0.656 - ETA: 14s - loss: 0.1839 - mean_iou: 0.656 - ETA: 14s - loss: 0.1870 - mean_iou: 0.656 - ETA: 14s - loss: 0.1889 - mean_iou: 0.656 - ETA: 14s - loss: 0.1862 - mean_iou: 0.656 - ETA: 13s - loss: 0.1845 - mean_iou: 0.656 - ETA: 13s - loss: 0.1824 - mean_iou: 0.656 - ETA: 13s - loss: 0.1826 - mean_iou: 0.656 - ETA: 13s - loss: 0.1809 - mean_iou: 0.656 - ETA: 12s - loss: 0.1783 - mean_iou: 0.656 - ETA: 12s - loss: 0.1786 - mean_iou: 0.656 - ETA: 12s - loss: 0.1775 - mean_iou: 0.656 - ETA: 12s - loss: 0.1769 - mean_iou: 0.657 - ETA: 12s - loss: 0.1772 - mean_iou: 0.657 - ETA: 11s - loss: 0.1771 - mean_iou: 0.657 - ETA: 11s - loss: 0.1766 - mean_iou: 0.657 - ETA: 11s - loss: 0.1792 - mean_iou: 0.657 - ETA: 11s - loss: 0.1793 - mean_iou: 0.657 - ETA: 10s - loss: 0.1802 - mean_iou: 0.657 - ETA: 10s - loss: 0.1808 - mean_iou: 0.657 - ETA: 10s - loss: 0.1812 - mean_iou: 0.657 - ETA: 10s - loss: 0.1812 - mean_iou: 0.657 - ETA: 9s - loss: 0.1803 - mean_iou: 0.657 - ETA: 9s - loss: 0.1788 - mean_iou: 0.65 - ETA: 9s - loss: 0.1782 - mean_iou: 0.65 - ETA: 9s - loss: 0.1795 - mean_iou: 0.65 - ETA: 8s - loss: 0.1801 - mean_iou: 0.65 - ETA: 8s - loss: 0.1805 - mean_iou: 0.65 - ETA: 8s - loss: 0.1800 - mean_iou: 0.65 - ETA: 8s - loss: 0.1802 - mean_iou: 0.65 - ETA: 7s - loss: 0.1817 - mean_iou: 0.65 - ETA: 7s - loss: 0.1814 - mean_iou: 0.65 - ETA: 7s - loss: 0.1812 - mean_iou: 0.65 - ETA: 7s - loss: 0.1808 - mean_iou: 0.65 - ETA: 6s - loss: 0.1801 - mean_iou: 0.65 - ETA: 6s - loss: 0.1795 - mean_iou: 0.65 - ETA: 6s - loss: 0.1792 - mean_iou: 0.65 - ETA: 6s - loss: 0.1786 - mean_iou: 0.65 - ETA: 5s - loss: 0.1788 - mean_iou: 0.65 - ETA: 5s - loss: 0.1780 - mean_iou: 0.65 - ETA: 5s - loss: 0.1780 - mean_iou: 0.65 - ETA: 5s - loss: 0.1780 - mean_iou: 0.65 - ETA: 4s - loss: 0.1773 - mean_iou: 0.65 - ETA: 4s - loss: 0.1781 - mean_iou: 0.65 - ETA: 4s - loss: 0.1781 - mean_iou: 0.65 - ETA: 4s - loss: 0.1782 - mean_iou: 0.65 - ETA: 3s - loss: 0.1777 - mean_iou: 0.65 - ETA: 3s - loss: 0.1774 - mean_iou: 0.65 - ETA: 3s - loss: 0.1774 - mean_iou: 0.65 - ETA: 3s - loss: 0.1783 - mean_iou: 0.65 - ETA: 2s - loss: 0.1779 - mean_iou: 0.65 - ETA: 2s - loss: 0.1783 - mean_iou: 0.65 - ETA: 2s - loss: 0.1778 - mean_iou: 0.65 - ETA: 2s - loss: 0.1778 - mean_iou: 0.65 - ETA: 1s - loss: 0.1784 - mean_iou: 0.65 - ETA: 1s - loss: 0.1784 - mean_iou: 0.65 - ETA: 1s - loss: 0.1786 - mean_iou: 0.65 - ETA: 1s - loss: 0.1782 - mean_iou: 0.65 - ETA: 0s - loss: 0.1783 - mean_iou: 0.65 - ETA: 0s - loss: 0.1783 - mean_iou: 0.65 - ETA: 0s - loss: 0.1783 - mean_iou: 0.65 - ETA: 0s - loss: 0.1786 - mean_iou: 0.65 - 19s 16ms/step - loss: 0.1791 - mean_iou: 0.6599 - val_loss: 0.2419 - val_mean_iou: 0.6645\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1987 - mean_iou: 0.664 - ETA: 17s - loss: 0.1616 - mean_iou: 0.665 - ETA: 17s - loss: 0.1768 - mean_iou: 0.665 - ETA: 16s - loss: 0.1798 - mean_iou: 0.665 - ETA: 16s - loss: 0.1838 - mean_iou: 0.665 - ETA: 16s - loss: 0.1792 - mean_iou: 0.665 - ETA: 16s - loss: 0.1763 - mean_iou: 0.665 - ETA: 15s - loss: 0.1722 - mean_iou: 0.665 - ETA: 15s - loss: 0.1704 - mean_iou: 0.665 - ETA: 15s - loss: 0.1730 - mean_iou: 0.665 - ETA: 15s - loss: 0.1712 - mean_iou: 0.665 - ETA: 14s - loss: 0.1674 - mean_iou: 0.665 - ETA: 14s - loss: 0.1677 - mean_iou: 0.665 - ETA: 14s - loss: 0.1703 - mean_iou: 0.665 - ETA: 14s - loss: 0.1715 - mean_iou: 0.665 - ETA: 13s - loss: 0.1700 - mean_iou: 0.665 - ETA: 13s - loss: 0.1730 - mean_iou: 0.665 - ETA: 13s - loss: 0.1719 - mean_iou: 0.665 - ETA: 13s - loss: 0.1712 - mean_iou: 0.665 - ETA: 12s - loss: 0.1708 - mean_iou: 0.666 - ETA: 12s - loss: 0.1689 - mean_iou: 0.666 - ETA: 12s - loss: 0.1678 - mean_iou: 0.666 - ETA: 12s - loss: 0.1675 - mean_iou: 0.666 - ETA: 12s - loss: 0.1660 - mean_iou: 0.666 - ETA: 11s - loss: 0.1650 - mean_iou: 0.666 - ETA: 11s - loss: 0.1672 - mean_iou: 0.666 - ETA: 11s - loss: 0.1663 - mean_iou: 0.666 - ETA: 11s - loss: 0.1664 - mean_iou: 0.666 - ETA: 11s - loss: 0.1671 - mean_iou: 0.666 - ETA: 10s - loss: 0.1658 - mean_iou: 0.666 - ETA: 10s - loss: 0.1655 - mean_iou: 0.666 - ETA: 10s - loss: 0.1679 - mean_iou: 0.666 - ETA: 10s - loss: 0.1680 - mean_iou: 0.666 - ETA: 9s - loss: 0.1672 - mean_iou: 0.666 - ETA: 9s - loss: 0.1696 - mean_iou: 0.66 - ETA: 9s - loss: 0.1687 - mean_iou: 0.66 - ETA: 9s - loss: 0.1691 - mean_iou: 0.66 - ETA: 8s - loss: 0.1698 - mean_iou: 0.66 - ETA: 8s - loss: 0.1687 - mean_iou: 0.66 - ETA: 8s - loss: 0.1686 - mean_iou: 0.66 - ETA: 8s - loss: 0.1687 - mean_iou: 0.66 - ETA: 7s - loss: 0.1693 - mean_iou: 0.66 - ETA: 7s - loss: 0.1702 - mean_iou: 0.66 - ETA: 7s - loss: 0.1697 - mean_iou: 0.66 - ETA: 7s - loss: 0.1687 - mean_iou: 0.66 - ETA: 6s - loss: 0.1685 - mean_iou: 0.66 - ETA: 6s - loss: 0.1679 - mean_iou: 0.66 - ETA: 6s - loss: 0.1677 - mean_iou: 0.66 - ETA: 6s - loss: 0.1681 - mean_iou: 0.66 - ETA: 5s - loss: 0.1675 - mean_iou: 0.66 - ETA: 5s - loss: 0.1673 - mean_iou: 0.66 - ETA: 5s - loss: 0.1677 - mean_iou: 0.66 - ETA: 5s - loss: 0.1674 - mean_iou: 0.66 - ETA: 4s - loss: 0.1676 - mean_iou: 0.66 - ETA: 4s - loss: 0.1672 - mean_iou: 0.66 - ETA: 4s - loss: 0.1672 - mean_iou: 0.66 - ETA: 4s - loss: 0.1666 - mean_iou: 0.66 - ETA: 3s - loss: 0.1659 - mean_iou: 0.66 - ETA: 3s - loss: 0.1670 - mean_iou: 0.66 - ETA: 3s - loss: 0.1663 - mean_iou: 0.66 - ETA: 3s - loss: 0.1658 - mean_iou: 0.66 - ETA: 2s - loss: 0.1657 - mean_iou: 0.66 - ETA: 2s - loss: 0.1659 - mean_iou: 0.66 - ETA: 2s - loss: 0.1664 - mean_iou: 0.66 - ETA: 2s - loss: 0.1668 - mean_iou: 0.66 - ETA: 1s - loss: 0.1665 - mean_iou: 0.66 - ETA: 1s - loss: 0.1665 - mean_iou: 0.66 - ETA: 1s - loss: 0.1672 - mean_iou: 0.66 - ETA: 1s - loss: 0.1671 - mean_iou: 0.66 - ETA: 0s - loss: 0.1678 - mean_iou: 0.66 - ETA: 0s - loss: 0.1683 - mean_iou: 0.66 - ETA: 0s - loss: 0.1685 - mean_iou: 0.66 - ETA: 0s - loss: 0.1690 - mean_iou: 0.66 - 19s 16ms/step - loss: 0.1686 - mean_iou: 0.6690 - val_loss: 0.2473 - val_mean_iou: 0.6733\n",
      "Epoch 18/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1429 - mean_iou: 0.673 - ETA: 18s - loss: 0.1399 - mean_iou: 0.673 - ETA: 18s - loss: 0.1694 - mean_iou: 0.673 - ETA: 17s - loss: 0.1596 - mean_iou: 0.673 - ETA: 17s - loss: 0.1627 - mean_iou: 0.673 - ETA: 16s - loss: 0.1633 - mean_iou: 0.674 - ETA: 16s - loss: 0.1597 - mean_iou: 0.674 - ETA: 16s - loss: 0.1603 - mean_iou: 0.674 - ETA: 16s - loss: 0.1613 - mean_iou: 0.674 - ETA: 15s - loss: 0.1632 - mean_iou: 0.674 - ETA: 15s - loss: 0.1635 - mean_iou: 0.674 - ETA: 15s - loss: 0.1653 - mean_iou: 0.674 - ETA: 15s - loss: 0.1632 - mean_iou: 0.674 - ETA: 15s - loss: 0.1633 - mean_iou: 0.674 - ETA: 14s - loss: 0.1647 - mean_iou: 0.674 - ETA: 14s - loss: 0.1634 - mean_iou: 0.674 - ETA: 14s - loss: 0.1636 - mean_iou: 0.674 - ETA: 13s - loss: 0.1662 - mean_iou: 0.674 - ETA: 13s - loss: 0.1659 - mean_iou: 0.674 - ETA: 13s - loss: 0.1652 - mean_iou: 0.674 - ETA: 13s - loss: 0.1654 - mean_iou: 0.674 - ETA: 12s - loss: 0.1665 - mean_iou: 0.674 - ETA: 12s - loss: 0.1668 - mean_iou: 0.674 - ETA: 12s - loss: 0.1681 - mean_iou: 0.674 - ETA: 12s - loss: 0.1660 - mean_iou: 0.674 - ETA: 11s - loss: 0.1655 - mean_iou: 0.675 - ETA: 11s - loss: 0.1667 - mean_iou: 0.675 - ETA: 11s - loss: 0.1667 - mean_iou: 0.675 - ETA: 11s - loss: 0.1665 - mean_iou: 0.675 - ETA: 10s - loss: 0.1670 - mean_iou: 0.675 - ETA: 10s - loss: 0.1669 - mean_iou: 0.675 - ETA: 10s - loss: 0.1678 - mean_iou: 0.675 - ETA: 10s - loss: 0.1678 - mean_iou: 0.675 - ETA: 9s - loss: 0.1681 - mean_iou: 0.675 - ETA: 9s - loss: 0.1679 - mean_iou: 0.67 - ETA: 9s - loss: 0.1675 - mean_iou: 0.67 - ETA: 9s - loss: 0.1682 - mean_iou: 0.67 - ETA: 8s - loss: 0.1681 - mean_iou: 0.67 - ETA: 8s - loss: 0.1697 - mean_iou: 0.67 - ETA: 8s - loss: 0.1705 - mean_iou: 0.67 - ETA: 8s - loss: 0.1716 - mean_iou: 0.67 - ETA: 7s - loss: 0.1717 - mean_iou: 0.67 - ETA: 7s - loss: 0.1702 - mean_iou: 0.67 - ETA: 7s - loss: 0.1697 - mean_iou: 0.67 - ETA: 7s - loss: 0.1692 - mean_iou: 0.67 - ETA: 6s - loss: 0.1687 - mean_iou: 0.67 - ETA: 6s - loss: 0.1692 - mean_iou: 0.67 - ETA: 6s - loss: 0.1697 - mean_iou: 0.67 - ETA: 6s - loss: 0.1689 - mean_iou: 0.67 - ETA: 5s - loss: 0.1680 - mean_iou: 0.67 - ETA: 5s - loss: 0.1678 - mean_iou: 0.67 - ETA: 5s - loss: 0.1676 - mean_iou: 0.67 - ETA: 5s - loss: 0.1675 - mean_iou: 0.67 - ETA: 4s - loss: 0.1679 - mean_iou: 0.67 - ETA: 4s - loss: 0.1687 - mean_iou: 0.67 - ETA: 4s - loss: 0.1686 - mean_iou: 0.67 - ETA: 4s - loss: 0.1686 - mean_iou: 0.67 - ETA: 3s - loss: 0.1676 - mean_iou: 0.67 - ETA: 3s - loss: 0.1679 - mean_iou: 0.67 - ETA: 3s - loss: 0.1690 - mean_iou: 0.67 - ETA: 3s - loss: 0.1689 - mean_iou: 0.67 - ETA: 2s - loss: 0.1691 - mean_iou: 0.67 - ETA: 2s - loss: 0.1689 - mean_iou: 0.67 - ETA: 2s - loss: 0.1686 - mean_iou: 0.67 - ETA: 2s - loss: 0.1694 - mean_iou: 0.67 - ETA: 1s - loss: 0.1692 - mean_iou: 0.67 - ETA: 1s - loss: 0.1691 - mean_iou: 0.67 - ETA: 1s - loss: 0.1692 - mean_iou: 0.67 - ETA: 1s - loss: 0.1691 - mean_iou: 0.67 - ETA: 0s - loss: 0.1694 - mean_iou: 0.67 - ETA: 0s - loss: 0.1700 - mean_iou: 0.67 - ETA: 0s - loss: 0.1701 - mean_iou: 0.67 - ETA: 0s - loss: 0.1702 - mean_iou: 0.67 - 19s 16ms/step - loss: 0.1697 - mean_iou: 0.6773 - val_loss: 0.2203 - val_mean_iou: 0.6811\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1815 - mean_iou: 0.681 - ETA: 17s - loss: 0.1501 - mean_iou: 0.681 - ETA: 17s - loss: 0.1510 - mean_iou: 0.681 - ETA: 17s - loss: 0.1580 - mean_iou: 0.681 - ETA: 17s - loss: 0.1620 - mean_iou: 0.681 - ETA: 16s - loss: 0.1586 - mean_iou: 0.681 - ETA: 16s - loss: 0.1660 - mean_iou: 0.681 - ETA: 16s - loss: 0.1735 - mean_iou: 0.681 - ETA: 16s - loss: 0.1745 - mean_iou: 0.681 - ETA: 15s - loss: 0.1724 - mean_iou: 0.681 - ETA: 15s - loss: 0.1766 - mean_iou: 0.681 - ETA: 15s - loss: 0.1778 - mean_iou: 0.682 - ETA: 15s - loss: 0.1756 - mean_iou: 0.682 - ETA: 15s - loss: 0.1732 - mean_iou: 0.682 - ETA: 14s - loss: 0.1725 - mean_iou: 0.682 - ETA: 14s - loss: 0.1726 - mean_iou: 0.682 - ETA: 14s - loss: 0.1768 - mean_iou: 0.682 - ETA: 14s - loss: 0.1751 - mean_iou: 0.682 - ETA: 13s - loss: 0.1743 - mean_iou: 0.682 - ETA: 13s - loss: 0.1730 - mean_iou: 0.682 - ETA: 13s - loss: 0.1758 - mean_iou: 0.682 - ETA: 12s - loss: 0.1724 - mean_iou: 0.682 - ETA: 12s - loss: 0.1728 - mean_iou: 0.682 - ETA: 12s - loss: 0.1710 - mean_iou: 0.682 - ETA: 12s - loss: 0.1706 - mean_iou: 0.682 - ETA: 11s - loss: 0.1707 - mean_iou: 0.682 - ETA: 11s - loss: 0.1707 - mean_iou: 0.682 - ETA: 11s - loss: 0.1719 - mean_iou: 0.682 - ETA: 11s - loss: 0.1717 - mean_iou: 0.682 - ETA: 10s - loss: 0.1723 - mean_iou: 0.682 - ETA: 10s - loss: 0.1717 - mean_iou: 0.682 - ETA: 10s - loss: 0.1706 - mean_iou: 0.682 - ETA: 10s - loss: 0.1716 - mean_iou: 0.682 - ETA: 9s - loss: 0.1705 - mean_iou: 0.682 - ETA: 9s - loss: 0.1693 - mean_iou: 0.68 - ETA: 9s - loss: 0.1696 - mean_iou: 0.68 - ETA: 9s - loss: 0.1685 - mean_iou: 0.68 - ETA: 8s - loss: 0.1672 - mean_iou: 0.68 - ETA: 8s - loss: 0.1667 - mean_iou: 0.68 - ETA: 8s - loss: 0.1661 - mean_iou: 0.68 - ETA: 8s - loss: 0.1667 - mean_iou: 0.68 - ETA: 7s - loss: 0.1664 - mean_iou: 0.68 - ETA: 7s - loss: 0.1670 - mean_iou: 0.68 - ETA: 7s - loss: 0.1671 - mean_iou: 0.68 - ETA: 7s - loss: 0.1665 - mean_iou: 0.68 - ETA: 6s - loss: 0.1659 - mean_iou: 0.68 - ETA: 6s - loss: 0.1658 - mean_iou: 0.68 - ETA: 6s - loss: 0.1661 - mean_iou: 0.68 - ETA: 6s - loss: 0.1653 - mean_iou: 0.68 - ETA: 5s - loss: 0.1658 - mean_iou: 0.68 - ETA: 5s - loss: 0.1652 - mean_iou: 0.68 - ETA: 5s - loss: 0.1656 - mean_iou: 0.68 - ETA: 5s - loss: 0.1654 - mean_iou: 0.68 - ETA: 4s - loss: 0.1651 - mean_iou: 0.68 - ETA: 4s - loss: 0.1643 - mean_iou: 0.68 - ETA: 4s - loss: 0.1646 - mean_iou: 0.68 - ETA: 4s - loss: 0.1636 - mean_iou: 0.68 - ETA: 3s - loss: 0.1629 - mean_iou: 0.68 - ETA: 3s - loss: 0.1630 - mean_iou: 0.68 - ETA: 3s - loss: 0.1620 - mean_iou: 0.68 - ETA: 3s - loss: 0.1617 - mean_iou: 0.68 - ETA: 2s - loss: 0.1612 - mean_iou: 0.68 - ETA: 2s - loss: 0.1615 - mean_iou: 0.68 - ETA: 2s - loss: 0.1608 - mean_iou: 0.68 - ETA: 2s - loss: 0.1608 - mean_iou: 0.68 - ETA: 1s - loss: 0.1605 - mean_iou: 0.68 - ETA: 1s - loss: 0.1605 - mean_iou: 0.68 - ETA: 1s - loss: 0.1603 - mean_iou: 0.68 - ETA: 1s - loss: 0.1611 - mean_iou: 0.68 - ETA: 0s - loss: 0.1609 - mean_iou: 0.68 - ETA: 0s - loss: 0.1604 - mean_iou: 0.68 - ETA: 0s - loss: 0.1604 - mean_iou: 0.68 - ETA: 0s - loss: 0.1600 - mean_iou: 0.68 - 19s 16ms/step - loss: 0.1598 - mean_iou: 0.6848 - val_loss: 0.2513 - val_mean_iou: 0.6886\n",
      "Epoch 20/50\n",
      "1183/1183 [==============================] - ETA: 16s - loss: 0.1109 - mean_iou: 0.688 - ETA: 17s - loss: 0.1323 - mean_iou: 0.689 - ETA: 16s - loss: 0.1432 - mean_iou: 0.689 - ETA: 16s - loss: 0.1591 - mean_iou: 0.689 - ETA: 16s - loss: 0.1549 - mean_iou: 0.689 - ETA: 16s - loss: 0.1546 - mean_iou: 0.689 - ETA: 16s - loss: 0.1481 - mean_iou: 0.689 - ETA: 15s - loss: 0.1557 - mean_iou: 0.689 - ETA: 15s - loss: 0.1517 - mean_iou: 0.689 - ETA: 15s - loss: 0.1484 - mean_iou: 0.689 - ETA: 15s - loss: 0.1498 - mean_iou: 0.689 - ETA: 15s - loss: 0.1483 - mean_iou: 0.689 - ETA: 14s - loss: 0.1457 - mean_iou: 0.689 - ETA: 14s - loss: 0.1424 - mean_iou: 0.689 - ETA: 14s - loss: 0.1423 - mean_iou: 0.689 - ETA: 13s - loss: 0.1428 - mean_iou: 0.689 - ETA: 13s - loss: 0.1433 - mean_iou: 0.689 - ETA: 13s - loss: 0.1417 - mean_iou: 0.689 - ETA: 13s - loss: 0.1410 - mean_iou: 0.689 - ETA: 13s - loss: 0.1409 - mean_iou: 0.689 - ETA: 12s - loss: 0.1419 - mean_iou: 0.689 - ETA: 12s - loss: 0.1437 - mean_iou: 0.690 - ETA: 12s - loss: 0.1437 - mean_iou: 0.690 - ETA: 12s - loss: 0.1462 - mean_iou: 0.690 - ETA: 11s - loss: 0.1453 - mean_iou: 0.690 - ETA: 11s - loss: 0.1446 - mean_iou: 0.690 - ETA: 11s - loss: 0.1446 - mean_iou: 0.690 - ETA: 11s - loss: 0.1448 - mean_iou: 0.690 - ETA: 10s - loss: 0.1455 - mean_iou: 0.690 - ETA: 10s - loss: 0.1444 - mean_iou: 0.690 - ETA: 10s - loss: 0.1443 - mean_iou: 0.690 - ETA: 10s - loss: 0.1444 - mean_iou: 0.690 - ETA: 9s - loss: 0.1440 - mean_iou: 0.690 - ETA: 9s - loss: 0.1437 - mean_iou: 0.69 - ETA: 9s - loss: 0.1433 - mean_iou: 0.69 - ETA: 9s - loss: 0.1428 - mean_iou: 0.69 - ETA: 8s - loss: 0.1442 - mean_iou: 0.69 - ETA: 8s - loss: 0.1452 - mean_iou: 0.69 - ETA: 8s - loss: 0.1447 - mean_iou: 0.69 - ETA: 8s - loss: 0.1443 - mean_iou: 0.69 - ETA: 8s - loss: 0.1452 - mean_iou: 0.69 - ETA: 7s - loss: 0.1451 - mean_iou: 0.69 - ETA: 7s - loss: 0.1451 - mean_iou: 0.69 - ETA: 7s - loss: 0.1461 - mean_iou: 0.69 - ETA: 7s - loss: 0.1457 - mean_iou: 0.69 - ETA: 6s - loss: 0.1460 - mean_iou: 0.69 - ETA: 6s - loss: 0.1450 - mean_iou: 0.69 - ETA: 6s - loss: 0.1457 - mean_iou: 0.69 - ETA: 6s - loss: 0.1465 - mean_iou: 0.69 - ETA: 5s - loss: 0.1466 - mean_iou: 0.69 - ETA: 5s - loss: 0.1467 - mean_iou: 0.69 - ETA: 5s - loss: 0.1463 - mean_iou: 0.69 - ETA: 5s - loss: 0.1460 - mean_iou: 0.69 - ETA: 4s - loss: 0.1455 - mean_iou: 0.69 - ETA: 4s - loss: 0.1457 - mean_iou: 0.69 - ETA: 4s - loss: 0.1458 - mean_iou: 0.69 - ETA: 4s - loss: 0.1458 - mean_iou: 0.69 - ETA: 3s - loss: 0.1457 - mean_iou: 0.69 - ETA: 3s - loss: 0.1462 - mean_iou: 0.69 - ETA: 3s - loss: 0.1460 - mean_iou: 0.69 - ETA: 3s - loss: 0.1465 - mean_iou: 0.69 - ETA: 2s - loss: 0.1471 - mean_iou: 0.69 - ETA: 2s - loss: 0.1471 - mean_iou: 0.69 - ETA: 2s - loss: 0.1482 - mean_iou: 0.69 - ETA: 2s - loss: 0.1480 - mean_iou: 0.69 - ETA: 1s - loss: 0.1472 - mean_iou: 0.69 - ETA: 1s - loss: 0.1481 - mean_iou: 0.69 - ETA: 1s - loss: 0.1484 - mean_iou: 0.69 - ETA: 1s - loss: 0.1482 - mean_iou: 0.69 - ETA: 0s - loss: 0.1481 - mean_iou: 0.69 - ETA: 0s - loss: 0.1478 - mean_iou: 0.69 - ETA: 0s - loss: 0.1474 - mean_iou: 0.69 - ETA: 0s - loss: 0.1471 - mean_iou: 0.69 - 19s 16ms/step - loss: 0.1476 - mean_iou: 0.6924 - val_loss: 0.2392 - val_mean_iou: 0.6960\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1015 - mean_iou: 0.696 - ETA: 17s - loss: 0.1105 - mean_iou: 0.696 - ETA: 17s - loss: 0.1189 - mean_iou: 0.696 - ETA: 17s - loss: 0.1223 - mean_iou: 0.696 - ETA: 17s - loss: 0.1239 - mean_iou: 0.696 - ETA: 17s - loss: 0.1261 - mean_iou: 0.696 - ETA: 16s - loss: 0.1249 - mean_iou: 0.696 - ETA: 16s - loss: 0.1278 - mean_iou: 0.696 - ETA: 16s - loss: 0.1289 - mean_iou: 0.696 - ETA: 16s - loss: 0.1283 - mean_iou: 0.696 - ETA: 15s - loss: 0.1271 - mean_iou: 0.696 - ETA: 15s - loss: 0.1277 - mean_iou: 0.696 - ETA: 15s - loss: 0.1252 - mean_iou: 0.697 - ETA: 14s - loss: 0.1267 - mean_iou: 0.697 - ETA: 14s - loss: 0.1277 - mean_iou: 0.697 - ETA: 14s - loss: 0.1285 - mean_iou: 0.697 - ETA: 14s - loss: 0.1287 - mean_iou: 0.697 - ETA: 13s - loss: 0.1315 - mean_iou: 0.697 - ETA: 13s - loss: 0.1306 - mean_iou: 0.697 - ETA: 13s - loss: 0.1291 - mean_iou: 0.697 - ETA: 13s - loss: 0.1297 - mean_iou: 0.697 - ETA: 12s - loss: 0.1294 - mean_iou: 0.697 - ETA: 12s - loss: 0.1276 - mean_iou: 0.697 - ETA: 12s - loss: 0.1299 - mean_iou: 0.697 - ETA: 12s - loss: 0.1321 - mean_iou: 0.697 - ETA: 11s - loss: 0.1322 - mean_iou: 0.697 - ETA: 11s - loss: 0.1328 - mean_iou: 0.697 - ETA: 11s - loss: 0.1326 - mean_iou: 0.697 - ETA: 11s - loss: 0.1327 - mean_iou: 0.697 - ETA: 10s - loss: 0.1326 - mean_iou: 0.697 - ETA: 10s - loss: 0.1327 - mean_iou: 0.697 - ETA: 10s - loss: 0.1315 - mean_iou: 0.697 - ETA: 10s - loss: 0.1313 - mean_iou: 0.697 - ETA: 9s - loss: 0.1308 - mean_iou: 0.697 - ETA: 9s - loss: 0.1303 - mean_iou: 0.69 - ETA: 9s - loss: 0.1301 - mean_iou: 0.69 - ETA: 9s - loss: 0.1306 - mean_iou: 0.69 - ETA: 9s - loss: 0.1306 - mean_iou: 0.69 - ETA: 8s - loss: 0.1312 - mean_iou: 0.69 - ETA: 8s - loss: 0.1310 - mean_iou: 0.69 - ETA: 8s - loss: 0.1312 - mean_iou: 0.69 - ETA: 8s - loss: 0.1309 - mean_iou: 0.69 - ETA: 7s - loss: 0.1303 - mean_iou: 0.69 - ETA: 7s - loss: 0.1303 - mean_iou: 0.69 - ETA: 7s - loss: 0.1297 - mean_iou: 0.69 - ETA: 7s - loss: 0.1291 - mean_iou: 0.69 - ETA: 6s - loss: 0.1292 - mean_iou: 0.69 - ETA: 6s - loss: 0.1286 - mean_iou: 0.69 - ETA: 6s - loss: 0.1285 - mean_iou: 0.69 - ETA: 6s - loss: 0.1286 - mean_iou: 0.69 - ETA: 5s - loss: 0.1293 - mean_iou: 0.69 - ETA: 5s - loss: 0.1303 - mean_iou: 0.69 - ETA: 5s - loss: 0.1311 - mean_iou: 0.69 - ETA: 4s - loss: 0.1310 - mean_iou: 0.69 - ETA: 4s - loss: 0.1313 - mean_iou: 0.69 - ETA: 4s - loss: 0.1313 - mean_iou: 0.69 - ETA: 4s - loss: 0.1309 - mean_iou: 0.69 - ETA: 3s - loss: 0.1309 - mean_iou: 0.69 - ETA: 3s - loss: 0.1304 - mean_iou: 0.69 - ETA: 3s - loss: 0.1302 - mean_iou: 0.69 - ETA: 3s - loss: 0.1300 - mean_iou: 0.69 - ETA: 2s - loss: 0.1290 - mean_iou: 0.69 - ETA: 2s - loss: 0.1287 - mean_iou: 0.69 - ETA: 2s - loss: 0.1292 - mean_iou: 0.69 - ETA: 2s - loss: 0.1293 - mean_iou: 0.69 - ETA: 1s - loss: 0.1293 - mean_iou: 0.69 - ETA: 1s - loss: 0.1293 - mean_iou: 0.69 - ETA: 1s - loss: 0.1294 - mean_iou: 0.69 - ETA: 1s - loss: 0.1293 - mean_iou: 0.69 - ETA: 0s - loss: 0.1293 - mean_iou: 0.69 - ETA: 0s - loss: 0.1296 - mean_iou: 0.69 - ETA: 0s - loss: 0.1296 - mean_iou: 0.69 - ETA: 0s - loss: 0.1300 - mean_iou: 0.69 - 19s 16ms/step - loss: 0.1300 - mean_iou: 0.6998 - val_loss: 0.2376 - val_mean_iou: 0.7034\n",
      "Epoch 22/50\n",
      "1183/1183 [==============================] - ETA: 18s - loss: 0.1118 - mean_iou: 0.703 - ETA: 16s - loss: 0.1138 - mean_iou: 0.703 - ETA: 16s - loss: 0.1090 - mean_iou: 0.703 - ETA: 16s - loss: 0.1164 - mean_iou: 0.703 - ETA: 16s - loss: 0.1198 - mean_iou: 0.703 - ETA: 16s - loss: 0.1169 - mean_iou: 0.703 - ETA: 16s - loss: 0.1135 - mean_iou: 0.704 - ETA: 16s - loss: 0.1158 - mean_iou: 0.704 - ETA: 16s - loss: 0.1209 - mean_iou: 0.704 - ETA: 15s - loss: 0.1206 - mean_iou: 0.704 - ETA: 15s - loss: 0.1175 - mean_iou: 0.704 - ETA: 15s - loss: 0.1181 - mean_iou: 0.704 - ETA: 15s - loss: 0.1183 - mean_iou: 0.704 - ETA: 14s - loss: 0.1176 - mean_iou: 0.704 - ETA: 14s - loss: 0.1187 - mean_iou: 0.704 - ETA: 14s - loss: 0.1167 - mean_iou: 0.704 - ETA: 14s - loss: 0.1171 - mean_iou: 0.704 - ETA: 13s - loss: 0.1158 - mean_iou: 0.704 - ETA: 13s - loss: 0.1156 - mean_iou: 0.704 - ETA: 13s - loss: 0.1166 - mean_iou: 0.704 - ETA: 13s - loss: 0.1167 - mean_iou: 0.704 - ETA: 13s - loss: 0.1155 - mean_iou: 0.704 - ETA: 12s - loss: 0.1155 - mean_iou: 0.704 - ETA: 12s - loss: 0.1146 - mean_iou: 0.704 - ETA: 12s - loss: 0.1158 - mean_iou: 0.704 - ETA: 12s - loss: 0.1160 - mean_iou: 0.704 - ETA: 11s - loss: 0.1161 - mean_iou: 0.704 - ETA: 11s - loss: 0.1176 - mean_iou: 0.704 - ETA: 11s - loss: 0.1196 - mean_iou: 0.705 - ETA: 11s - loss: 0.1207 - mean_iou: 0.705 - ETA: 10s - loss: 0.1206 - mean_iou: 0.705 - ETA: 10s - loss: 0.1202 - mean_iou: 0.705 - ETA: 10s - loss: 0.1197 - mean_iou: 0.705 - ETA: 10s - loss: 0.1198 - mean_iou: 0.705 - ETA: 9s - loss: 0.1197 - mean_iou: 0.705 - ETA: 9s - loss: 0.1191 - mean_iou: 0.70 - ETA: 9s - loss: 0.1202 - mean_iou: 0.70 - ETA: 9s - loss: 0.1198 - mean_iou: 0.70 - ETA: 8s - loss: 0.1193 - mean_iou: 0.70 - ETA: 8s - loss: 0.1192 - mean_iou: 0.70 - ETA: 8s - loss: 0.1195 - mean_iou: 0.70 - ETA: 8s - loss: 0.1191 - mean_iou: 0.70 - ETA: 7s - loss: 0.1194 - mean_iou: 0.70 - ETA: 7s - loss: 0.1192 - mean_iou: 0.70 - ETA: 7s - loss: 0.1191 - mean_iou: 0.70 - ETA: 6s - loss: 0.1195 - mean_iou: 0.70 - ETA: 6s - loss: 0.1201 - mean_iou: 0.70 - ETA: 6s - loss: 0.1200 - mean_iou: 0.70 - ETA: 6s - loss: 0.1197 - mean_iou: 0.70 - ETA: 5s - loss: 0.1195 - mean_iou: 0.70 - ETA: 5s - loss: 0.1196 - mean_iou: 0.70 - ETA: 5s - loss: 0.1199 - mean_iou: 0.70 - ETA: 5s - loss: 0.1197 - mean_iou: 0.70 - ETA: 4s - loss: 0.1193 - mean_iou: 0.70 - ETA: 4s - loss: 0.1190 - mean_iou: 0.70 - ETA: 4s - loss: 0.1184 - mean_iou: 0.70 - ETA: 4s - loss: 0.1185 - mean_iou: 0.70 - ETA: 3s - loss: 0.1177 - mean_iou: 0.70 - ETA: 3s - loss: 0.1176 - mean_iou: 0.70 - ETA: 3s - loss: 0.1177 - mean_iou: 0.70 - ETA: 3s - loss: 0.1178 - mean_iou: 0.70 - ETA: 2s - loss: 0.1183 - mean_iou: 0.70 - ETA: 2s - loss: 0.1180 - mean_iou: 0.70 - ETA: 2s - loss: 0.1180 - mean_iou: 0.70 - ETA: 2s - loss: 0.1183 - mean_iou: 0.70 - ETA: 1s - loss: 0.1186 - mean_iou: 0.70 - ETA: 1s - loss: 0.1185 - mean_iou: 0.70 - ETA: 1s - loss: 0.1185 - mean_iou: 0.70 - ETA: 1s - loss: 0.1192 - mean_iou: 0.70 - ETA: 0s - loss: 0.1196 - mean_iou: 0.70 - ETA: 0s - loss: 0.1195 - mean_iou: 0.70 - ETA: 0s - loss: 0.1195 - mean_iou: 0.70 - ETA: 0s - loss: 0.1193 - mean_iou: 0.70 - 19s 16ms/step - loss: 0.1192 - mean_iou: 0.7070 - val_loss: 0.2624 - val_mean_iou: 0.7105\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183/1183 [==============================] - ETA: 19s - loss: 0.0931 - mean_iou: 0.710 - ETA: 17s - loss: 0.0981 - mean_iou: 0.710 - ETA: 16s - loss: 0.0957 - mean_iou: 0.710 - ETA: 16s - loss: 0.1030 - mean_iou: 0.710 - ETA: 16s - loss: 0.1015 - mean_iou: 0.710 - ETA: 16s - loss: 0.1076 - mean_iou: 0.711 - ETA: 16s - loss: 0.1076 - mean_iou: 0.711 - ETA: 16s - loss: 0.1070 - mean_iou: 0.711 - ETA: 15s - loss: 0.1068 - mean_iou: 0.711 - ETA: 15s - loss: 0.1063 - mean_iou: 0.711 - ETA: 15s - loss: 0.1056 - mean_iou: 0.711 - ETA: 14s - loss: 0.1042 - mean_iou: 0.711 - ETA: 14s - loss: 0.1068 - mean_iou: 0.711 - ETA: 14s - loss: 0.1068 - mean_iou: 0.711 - ETA: 14s - loss: 0.1069 - mean_iou: 0.711 - ETA: 13s - loss: 0.1068 - mean_iou: 0.711 - ETA: 13s - loss: 0.1059 - mean_iou: 0.711 - ETA: 13s - loss: 0.1065 - mean_iou: 0.711 - ETA: 13s - loss: 0.1066 - mean_iou: 0.711 - ETA: 13s - loss: 0.1071 - mean_iou: 0.711 - ETA: 12s - loss: 0.1082 - mean_iou: 0.711 - ETA: 12s - loss: 0.1081 - mean_iou: 0.711 - ETA: 12s - loss: 0.1075 - mean_iou: 0.711 - ETA: 12s - loss: 0.1085 - mean_iou: 0.711 - ETA: 12s - loss: 0.1085 - mean_iou: 0.711 - ETA: 11s - loss: 0.1077 - mean_iou: 0.711 - ETA: 11s - loss: 0.1083 - mean_iou: 0.711 - ETA: 11s - loss: 0.1080 - mean_iou: 0.711 - ETA: 11s - loss: 0.1075 - mean_iou: 0.712 - ETA: 10s - loss: 0.1069 - mean_iou: 0.712 - ETA: 10s - loss: 0.1061 - mean_iou: 0.712 - ETA: 10s - loss: 0.1065 - mean_iou: 0.712 - ETA: 10s - loss: 0.1072 - mean_iou: 0.712 - ETA: 9s - loss: 0.1075 - mean_iou: 0.712 - ETA: 9s - loss: 0.1072 - mean_iou: 0.71 - ETA: 9s - loss: 0.1076 - mean_iou: 0.71 - ETA: 9s - loss: 0.1080 - mean_iou: 0.71 - ETA: 8s - loss: 0.1079 - mean_iou: 0.71 - ETA: 8s - loss: 0.1072 - mean_iou: 0.71 - ETA: 8s - loss: 0.1084 - mean_iou: 0.71 - ETA: 8s - loss: 0.1081 - mean_iou: 0.71 - ETA: 7s - loss: 0.1087 - mean_iou: 0.71 - ETA: 7s - loss: 0.1089 - mean_iou: 0.71 - ETA: 7s - loss: 0.1088 - mean_iou: 0.71 - ETA: 7s - loss: 0.1088 - mean_iou: 0.71 - ETA: 6s - loss: 0.1090 - mean_iou: 0.71 - ETA: 6s - loss: 0.1097 - mean_iou: 0.71 - ETA: 6s - loss: 0.1091 - mean_iou: 0.71 - ETA: 6s - loss: 0.1090 - mean_iou: 0.71 - ETA: 5s - loss: 0.1094 - mean_iou: 0.71 - ETA: 5s - loss: 0.1087 - mean_iou: 0.71 - ETA: 5s - loss: 0.1093 - mean_iou: 0.71 - ETA: 5s - loss: 0.1101 - mean_iou: 0.71 - ETA: 4s - loss: 0.1098 - mean_iou: 0.71 - ETA: 4s - loss: 0.1095 - mean_iou: 0.71 - ETA: 4s - loss: 0.1095 - mean_iou: 0.71 - ETA: 4s - loss: 0.1094 - mean_iou: 0.71 - ETA: 3s - loss: 0.1094 - mean_iou: 0.71 - ETA: 3s - loss: 0.1095 - mean_iou: 0.71 - ETA: 3s - loss: 0.1093 - mean_iou: 0.71 - ETA: 3s - loss: 0.1089 - mean_iou: 0.71 - ETA: 2s - loss: 0.1085 - mean_iou: 0.71 - ETA: 2s - loss: 0.1089 - mean_iou: 0.71 - ETA: 2s - loss: 0.1089 - mean_iou: 0.71 - ETA: 2s - loss: 0.1088 - mean_iou: 0.71 - ETA: 1s - loss: 0.1094 - mean_iou: 0.71 - ETA: 1s - loss: 0.1096 - mean_iou: 0.71 - ETA: 1s - loss: 0.1100 - mean_iou: 0.71 - ETA: 1s - loss: 0.1103 - mean_iou: 0.71 - ETA: 0s - loss: 0.1106 - mean_iou: 0.71 - ETA: 0s - loss: 0.1111 - mean_iou: 0.71 - ETA: 0s - loss: 0.1119 - mean_iou: 0.71 - ETA: 0s - loss: 0.1123 - mean_iou: 0.71 - 19s 16ms/step - loss: 0.1124 - mean_iou: 0.7139 - val_loss: 0.2398 - val_mean_iou: 0.7172\n"
     ]
    }
   ],
   "source": [
    "# Get train imgs and masks\n",
    "X_train = Get_IMGs('data\\\\train\\\\') \n",
    "Y_train = Get_Masks('data\\\\train_mask\\\\')\n",
    "\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_1.h5', verbose=0, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "                    callbacks=[checkpointer,earlystopper], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model on validation images, save to csv and get Dice metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 145/145 [00:02<00:00, 73.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 215.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice metric for valid imgs: 0.9338391916772382\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "valid_imgs = Get_IMGs('data\\\\valid\\\\') #get np.array with images\n",
    "valid_true_masks = Get_Masks('data\\\\valid_mask\\\\')#get np.array with masks\n",
    "\n",
    "valid_pred_masks = (model.predict(valid_imgs)> 0.5).astype(np.uint8) #get predicted masks\n",
    "\n",
    "# Save valid rle_masks to pred_valid_template.csv\n",
    "df = pd.DataFrame({\n",
    "        'id': [int(x.split('.')[0]) for x in next(os.walk('data\\\\valid\\\\'))[2]],\n",
    "        'rle_mask': [encode_rle(mask) for mask in np.squeeze(valid_pred_masks)]\n",
    "})\n",
    "df.to_csv('data/pred_valid_template.csv',index=False)  #save to csv\n",
    "\n",
    "#Check Dice metric\n",
    "Dice_metric = get_dice(np.squeeze(valid_true_masks), np.squeeze(valid_pred_masks))\n",
    "print('Dice metric for valid imgs:', Dice_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice metric for valid imgs: 0.9338"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image, true mask and predicted mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c5588eb27046b1ad1731dfacb1b00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=145), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(valid_imgs),1))\n",
    "def g(i=0):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('image')\n",
    "    plt.imshow(valid_imgs[i,:,:])\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('true mask')\n",
    "    plt.imshow(valid_true_masks[i,:,:,0])\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('mask predicted')\n",
    "    plt.imshow(valid_pred_masks[i,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get masks from test images and create examples.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 74.56it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = Get_IMGs('data/test/') \n",
    "\n",
    "# Predict masks for test imgs\n",
    "model = load_model('model_1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "test_pred_masks = model.predict(test_imgs)\n",
    "test_pred_masks = np.squeeze(test_pred_masks > 0.5).astype(np.uint8)*255 \n",
    "# without *255 masks, putted in example.html, will look like black rectangle\n",
    "\n",
    "# Save to html\n",
    "paths_to_imgs = sorted(glob(\"data\\\\test\\\\*\"))\n",
    "_ = get_html(paths_to_imgs, test_pred_masks, path_to_save=\"results\\\\example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
